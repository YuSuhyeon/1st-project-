"""
ğŸ¯ 2025 ì„œìš¸ ì•„íŒŒíŠ¸ ê°€ê²© ì˜ˆì¸¡ - 8í”¼ì²˜ ì „ì²˜ë¦¬
2022-2024 í•™ìŠµë°ì´í„°ë¡œë§Œ ì¸ì½”ë”© í•™ìŠµ
2025 ë°ì´í„°ëŠ” ìˆœìˆ˜ ì˜ˆì¸¡ íƒ€ê²Ÿ
"""

import pandas as pd
import numpy as np
import os
import re
from sklearn.preprocessing import LabelEncoder
import warnings
warnings.filterwarnings('ignore')

def preprocessing_for_2025_prediction():
    """
    2025 ì„œìš¸ ì•„íŒŒíŠ¸ ê°€ê²© ì˜ˆì¸¡ì„ ìœ„í•œ 8í”¼ì²˜ ì „ì²˜ë¦¬
    """
    
    print("ğŸ¯ 2025 ì„œìš¸ ì•„íŒŒíŠ¸ ê°€ê²© ì˜ˆì¸¡ ì „ì²˜ë¦¬!")
    print("ğŸ“š í•™ìŠµ: 2022-2024 ë°ì´í„°ë§Œ ì‚¬ìš©")
    print("ğŸ”® ì˜ˆì¸¡: 2025 ë°ì´í„° (ìˆœìˆ˜ íƒ€ê²Ÿ)")
    print("ğŸ¯ ëª©í‘œ: ì‹¤ì œ ë°°í¬ í™˜ê²½ê³¼ ë™ì¼í•œ ì¡°ê±´!")
    print("=" * 60)
    
    # 1. ë°ì´í„° ë¡œë“œ
    print("1ï¸âƒ£ ë°ì´í„° ë¡œë“œ")
    file_path = "data/raw/20250604_182224_seoul_real_estate.csv"
    
    if not os.path.exists(file_path):
        print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}")
        return None
    
    df = pd.read_csv(file_path)
    print(f"   ì›ë³¸ ë°ì´í„°: {df.shape}")
    
    # 2. ê¸°ë³¸ í”¼ì²˜ ìƒì„±
    print("\n2ï¸âƒ£ ê¸°ë³¸ í”¼ì²˜ ìƒì„±")
    
    # ê¸°ë³¸ í”¼ì²˜ ìƒì„±
    df['PRICE'] = df['PRICE_EUK'] * 10000
    df['CTRT_YEAR'] = pd.to_datetime(df['CTRT_DAY']).dt.year
    df['BUILDING_AGE'] = 2025 - df['ARCH_YR']  #ëª¨ë“  ì˜ˆì¸¡ì´ 2025ë…„ ê¸°ì¤€ì´ë¯€ë¡œ ê±´ë¬¼ë‚˜ì´ë„ 2025ë…„ ê¸°ì¤€ìœ¼ë¡œ ê³„ì‚°
    
    print(f"   í”¼ì²˜ ìƒì„± ì™„ë£Œ: PRICE, CTRT_YEAR, BUILDING_AGE")
    
    # 3. ğŸš¨ ë°ì´í„° ë¶„í•  ìš°ì„  (ë¦¬í‚¤ì§€ ë°©ì§€)
    print("\n3ï¸âƒ£ ğŸš¨ ë°ì´í„° ë¶„í•  ìš°ì„  (ë¦¬í‚¤ì§€ ë°©ì§€)")
    
    # ê¸°ë³¸ í•„ìˆ˜ ì¡°ê±´ë§Œ ë¨¼ì € í•„í„°ë§ (ë¦¬í‚¤ì§€ ì—†ëŠ” ì¡°ê±´ë“¤ë§Œ)
    print("   ê¸°ë³¸ í•„ìˆ˜ ì¡°ê±´ í•„í„°ë§...")
    initial_count = len(df)
    
    # ê±´ì¶•ë…„ë„ í•„í„°ë§
    df = df[(df['ARCH_YR'] > 0) & (df['ARCH_YR'] <= 2025)]
    
    # ê±´ë¬¼ë‚˜ì´ í•„í„°ë§ (ìŒìˆ˜ ë° ë¹„í˜„ì‹¤ì  ê°’ ì œê±°)
    df = df[(df['BUILDING_AGE'] >= 0) & (df['BUILDING_AGE'] <= 50)]
    
    # ê¸°íƒ€ ê¸°ë³¸ í•„í„°ë§
    df = df[(df['PYEONG'] > 0) & (df['PRICE'] > 0)]
    df = df.dropna(subset=['ARCH_YR', 'PYEONG', 'FLR'])
    
    print(f"   ê¸°ë³¸ í•„í„°ë§: {initial_count:,} â†’ {len(df):,}ê±´")
    
    # ì¦‰ì‹œ ë°ì´í„° ë¶„í• 
    train_data = df[df['CTRT_YEAR'] < 2025].copy()  # 2022-2024
    predict_data = df[df['CTRT_YEAR'] == 2025].copy()  # 2025
    
    print(f"   ğŸ“š í•™ìŠµ ë°ì´í„°: {len(train_data):,}ê±´ (2022-2024)")
    print(f"   ğŸ”® ì˜ˆì¸¡ ë°ì´í„°: {len(predict_data):,}ê±´ (2025)")
    print(f"   ğŸ“Š í•™ìŠµ/ì˜ˆì¸¡ ë¹„ìœ¨: {len(train_data)/(len(train_data)+len(predict_data))*100:.1f}% / {len(predict_data)/(len(train_data)+len(predict_data))*100:.1f}%")
    
    # 4. ê·¹ë‹¨ê°’ ì œê±° (í•™ìŠµ ë°ì´í„° ê¸°ì¤€ìœ¼ë¡œë§Œ - ë°ì´í„° ë¦¬í‚¤ì§€ ë°©ì§€)
    print("\n4ï¸âƒ£ ğŸ”§ ê·¹ë‹¨ê°’ ì œê±° (í•™ìŠµ ë°ì´í„° ê¸°ì¤€)")
    
    # í•™ìŠµ ë°ì´í„°ë¡œë§Œ ë¶„ìœ„ìˆ˜ ê³„ì‚°
    price_q01, price_q99 = train_data['PRICE'].quantile([0.01, 0.99])
    pyeong_q01, pyeong_q99 = train_data['PYEONG'].quantile([0.01, 0.99])
    
    print(f"   ê°€ê²© ê¸°ì¤€: {price_q01:,.0f} ~ {price_q99:,.0f}ë§Œì›")
    print(f"   í‰ìˆ˜ ê¸°ì¤€: {pyeong_q01:.1f} ~ {pyeong_q99:.1f}í‰")
    
    # í•™ìŠµ ë°ì´í„° ê·¹ë‹¨ê°’ ì œê±°
    train_before = len(train_data)
    train_data = train_data[
        (train_data['PRICE'] >= price_q01) & (train_data['PRICE'] <= price_q99) &
        (train_data['PYEONG'] >= pyeong_q01) & (train_data['PYEONG'] <= pyeong_q99)
    ]
    
    # ì˜ˆì¸¡ ë°ì´í„°ì—ë„ ë™ì¼í•œ ê¸°ì¤€ ì ìš©
    predict_before = len(predict_data)
    predict_data = predict_data[
        (predict_data['PRICE'] >= price_q01) & (predict_data['PRICE'] <= price_q99) &
        (predict_data['PYEONG'] >= pyeong_q01) & (predict_data['PYEONG'] <= pyeong_q99)
    ]
    
    print(f"   í•™ìŠµ ë°ì´í„° ê·¹ë‹¨ê°’ ì œê±°: {train_before:,} â†’ {len(train_data):,}ê±´")
    print(f"   ì˜ˆì¸¡ ë°ì´í„° ê·¹ë‹¨ê°’ ì œê±°: {predict_before:,} â†’ {len(predict_data):,}ê±´")
    print(f"   âœ… ì™„ì „í•œ ë°ì´í„° ëˆ„ì¶œ ë°©ì§€: í•™ìŠµ ë°ì´í„° ê¸°ì¤€ìœ¼ë¡œë§Œ ê·¹ë‹¨ê°’ ì œê±°")
    
    # 4. ë¸Œëœë“œ ë¶„ì„ (í•™ìŠµ ë°ì´í„°ë§Œ!)
    print("\n5ï¸âƒ£ ë¸Œëœë“œ ë¶„ì„ (í•™ìŠµ ë°ì´í„° ê¸°ì¤€)")
    
    # ë¸Œëœë“œ ë§¤í•‘ (ì›ë³¸ ë°©ì‹ ìœ ì§€)
    brand_mapping = {
        'ë˜ë¯¸ì•ˆ': r'ë˜ë¯¸ì•ˆ|RAEMIAN|raemian',
        'ìì´': r'ìì´|XI|xi',
        'eí¸í•œì„¸ìƒ': r'eí¸í•œì„¸ìƒ|e-í¸í•œì„¸ìƒ|ì´í¸í•œì„¸ìƒ|eí¸í•œ|Eí¸í•œì„¸ìƒ',
        'íìŠ¤í…Œì´íŠ¸': r'íìŠ¤í…Œì´íŠ¸|HILLSTATE|hillstate',
        'ì•„í¬ë¡œ': r'ì•„í¬ë¡œ|ACRO|acro',
        'ë”ìƒµ': r'ë”ìƒµ|THEìƒµ|THE SHARP|SHARP',
        'í‘¸ë¥´ì§€ì˜¤': r'í‘¸ë¥´ì§€ì˜¤|PRUGIO|prugio',
        'ë¡¯ë°ìºìŠ¬': r'ë¡¯ë°ìºìŠ¬|ë¡¯ë°|LOTTE|lotte',
        'ìˆ˜ìì¸': r'ìˆ˜ìì¸|í•œì–‘ìˆ˜ìì¸|ìˆ˜ìì¸ë””ì—íŠ¸ë¥´',
        'ìœ„ë¸Œ': r'ìœ„ë¸Œ|WEVE|weve',
        'ì•„ì´íŒŒí¬': r'ì•„ì´íŒŒí¬|i-park|I-PARK|ipark|IPARK',
        'ì„¼íŠ¸ëŸ´': r'ì„¼íŠ¸ëŸ´|CENTRAL|central',
        'í¬ë ˆìŠ¤íŠ¸': r'í¬ë ˆìŠ¤íŠ¸|FOREST|forest',
        'í˜„ëŒ€': r'í˜„ëŒ€',
        'ì‚¼ì„±': r'ì‚¼ì„±',
        'í•œì–‘': r'í•œì–‘',
        'ë‘ì‚°': r'ë‘ì‚°',
        'ëŒ€ìš°': r'ëŒ€ìš°',
        'ë””ì—ì´ì¹˜': r'ë””ì—ì´ì¹˜|D\'H|DH',
        'ìŠ¤ì¹´ì´': r'ìŠ¤ì¹´ì´|SKY|sky',
        'íŒŒí¬': r'íŒŒí¬|PARK|park',
        'íƒ€ì›Œ': r'íƒ€ì›Œ|TOWER|tower'
    }
    
    def extract_advanced_brand(building_name):
        if pd.isna(building_name):
            return 'ë¸Œëœë“œì—†ìŒ'  # ëª…ì¹­ ê°œì„ 
        
        building_name = str(building_name)
        
        # ì •ê·œì‹ìœ¼ë¡œ ë¸Œëœë“œ ë§¤ì¹­
        for brand, pattern in brand_mapping.items():
            if re.search(pattern, building_name, re.IGNORECASE):
                return brand
        
        return 'ë¸Œëœë“œì—†ìŒ'  # ëª…ì¹­ ê°œì„ 
    
    # ë¸Œëœë“œ ì¶”ì¶œ
    train_data.loc[:, 'BRAND_NAME'] = train_data['BLDG_NM'].apply(extract_advanced_brand)
    predict_data.loc[:, 'BRAND_NAME'] = predict_data['BLDG_NM'].apply(extract_advanced_brand)
    
    # ë¸Œëœë“œë³„ ê°€ê²© ë¶„ì„ (í•™ìŠµ ë°ì´í„°ë§Œ!)
    train_data['PRICE_PER_PYEONG'] = train_data['PRICE'] / train_data['PYEONG']
    
    brand_stats = train_data.groupby('BRAND_NAME').agg({
        'PRICE_PER_PYEONG': ['mean', 'count'],
        'PRICE': 'mean'
    }).round(0)
    
    brand_stats.columns = ['í‰ë‹¹ê°€ê²©_í‰ê· ', 'ê±°ë˜ê±´ìˆ˜', 'ì´ê°€ê²©_í‰ê· ']
    brand_stats = brand_stats[brand_stats['ê±°ë˜ê±´ìˆ˜'] >= 30]  # 30ê±´ ì´ìƒ
    
    print(f"   ë¸Œëœë“œë³„ ê°€ê²© ì •ë³´ (í•™ìŠµ ë°ì´í„°, 30ê±´ ì´ìƒ):")
    brand_sorted = brand_stats.sort_values('í‰ë‹¹ê°€ê²©_í‰ê· ', ascending=False)
    for brand, stats in brand_sorted.head(10).iterrows():
        print(f"   {brand}: í‰ë‹¹ {stats['í‰ë‹¹ê°€ê²©_í‰ê· ']:,.0f}ë§Œì› ({stats['ê±°ë˜ê±´ìˆ˜']:,.0f}ê±´)")
    
    # ë¸Œëœë“œ ì ìˆ˜ ê³„ì‚°
    overall_mean_per_pyeong = train_data['PRICE_PER_PYEONG'].mean()
    
    def get_brand_score(brand_name):
        if brand_name not in brand_stats.index:
            return 1  # ë¸Œëœë“œì—†ìŒ = 1ì 
        
        brand_avg = brand_stats.loc[brand_name, 'í‰ë‹¹ê°€ê²©_í‰ê· ']
        premium_ratio = brand_avg / overall_mean_per_pyeong
        
        if premium_ratio >= 1.3:    return 5    # ìµœê³ ê¸‰ (30% ì´ìƒ)
        elif premium_ratio >= 1.15: return 4    # ê³ ê¸‰ (15-30%)
        elif premium_ratio >= 1.0:  return 3    # ì¤‘ê¸‰ (í‰ê· )
        elif premium_ratio >= 0.9:  return 2    # ì¼ë°˜ (-10%)
        else:                       return 1    # ì €ê°€ (-10% ì´í•˜)
    
    # ì ìˆ˜ ì ìš©
    train_data.loc[:, 'BRAND_SCORE'] = train_data['BRAND_NAME'].apply(get_brand_score)
    predict_data.loc[:, 'BRAND_SCORE'] = predict_data['BRAND_NAME'].apply(get_brand_score)
    
    # ë¸Œëœë“œ ì ìˆ˜ ë¶„í¬
    brand_dist = train_data['BRAND_SCORE'].value_counts().sort_index()
    print(f"\n   ë¸Œëœë“œ ì ìˆ˜ ë¶„í¬ (í•™ìŠµ ë°ì´í„°):")
    for score, count in brand_dist.items():
        pct = count / len(train_data) * 100
        print(f"   {score}ì : {count:,}ê±´ ({pct:.1f}%)")
    
    # 5. êµ¬ë³„ ì§€í•˜ì²  ì ‘ê·¼ì„± ì ìˆ˜
    print("\n6ï¸âƒ£ êµ¬ë³„ ì§€í•˜ì²  ì ‘ê·¼ì„± ì ìˆ˜")
    
    # ğŸ“ ì§€í•˜ì²  ì ‘ê·¼ì„± ì ìˆ˜ ì‚°ì • ê·¼ê±°:
    # - ì„œìš¸ì‹œ ì§€í•˜ì²  ë…¸ì„ ë„ ë° í™˜ìŠ¹ì—­ ë¶„ì„ ê¸°ë°˜
    # - ìš´í–‰ ë…¸ì„  ìˆ˜: ê°•ë‚¨êµ¬(2,3,7,9í˜¸ì„ +ë¶„ë‹¹ì„ ), ì„œì´ˆêµ¬(2,3,7í˜¸ì„ +ë¶„ë‹¹ì„ ), ì¤‘êµ¬(1,2,4,5,6í˜¸ì„ ), ì¢…ë¡œêµ¬(1,3,5,6í˜¸ì„ )
    # - í™˜ìŠ¹ì—­ ë°€ë„: ê°•ë‚¨ì—­(2,ë¶„ë‹¹ì„ ), êµëŒ€ì—­(2,3í˜¸ì„ ), ì„ì§€ë¡œì…êµ¬(2í˜¸ì„ ), ì¢…ê°ì—­(1í˜¸ì„ ) ë“±
    # - ë„ì‹¬ ì ‘ê·¼ì„±: CBD(ì¤‘êµ¬,ì¢…ë¡œêµ¬) > ê°•ë‚¨ê¶Œ(ê°•ë‚¨,ì„œì´ˆ) > ì˜ë“±í¬ê¶Œ > ê¸°íƒ€
    ''' ì§€í•˜ì²  ì ‘ê·¼ì„± ì ìˆ˜ ì‚°ì • ê¸°ì¤€: ìš´í–‰ ë…¸ì„  ìˆ˜, í™˜ìŠ¹ì—­ ë°€ë„, ë„ì‹¬ ì ‘ê·¼ì„±ì„ ì¢…í•© ê³ ë ¤
    - 5ì : ë‹¤ìˆ˜ ë…¸ì„ (4ê°œ ì´ìƒ) + ì£¼ìš” í™˜ìŠ¹ì—­ ë°€ì§‘
    - 4ì : ì£¼ìš” ë…¸ì„ (2-3ê°œ) + í™˜ìŠ¹ì—­ ì¡´ì¬
    - 3ì : ì¼ë°˜ ë…¸ì„ (1-2ê°œ) + ê¸°ë³¸ ì—­ì„¸ê¶Œ
    - 2ì : ì™¸ê³½ ì§€ì—­, ì œí•œì  ì ‘ê·¼ì„±
    
    # êµ¬ë³„ ì§€í•˜ì²  ë…¸ì„  ì •ë³´ (ì‹¤ì œ ë°ì´í„° ê¸°ë°˜)
    subway_line_info = {
        # 5ì : ìµœê³  ì ‘ê·¼ì„± (4ê°œ ì´ìƒ ë…¸ì„ , ì£¼ìš” í™˜ìŠ¹ì—­ ë°€ì§‘)
        'ê°•ë‚¨êµ¬': {'lines': ['2í˜¸ì„ ', '3í˜¸ì„ ', '7í˜¸ì„ ', '9í˜¸ì„ '], 'major_stations': ['ê°•ë‚¨', 'ì—­ì‚¼', 'ì„ ë¦‰']},
        'ì„œì´ˆêµ¬': {'lines': ['2í˜¸ì„ ', '3í˜¸ì„ ', '7í˜¸ì„ '], 'major_stations': ['ê°•ë‚¨', 'êµëŒ€', 'ì‚¬ë‹¹']},
        'ì¤‘êµ¬': {'lines': ['1í˜¸ì„ ', '2í˜¸ì„ ', '4í˜¸ì„ ', '5í˜¸ì„ '], 'major_stations': ['ì„œìš¸ì—­', 'ì„ì§€ë¡œ3ê°€', 'ë™ëŒ€ë¬¸ì—­ì‚¬ë¬¸í™”ê³µì›']},
        'ì¢…ë¡œêµ¬': {'lines': ['1í˜¸ì„ ', '3í˜¸ì„ ', '5í˜¸ì„ ', '6í˜¸ì„ '], 'major_stations': ['ì¢…ê°', 'ì„ì§€ë¡œ3ê°€', 'ê´‘í™”ë¬¸']},
        
        # 4ì : ìš°ìˆ˜ ì ‘ê·¼ì„± (2-3ê°œ ì£¼ìš” ë…¸ì„ )
        'ì†¡íŒŒêµ¬': {'lines': ['2í˜¸ì„ ', '5í˜¸ì„ ', '8í˜¸ì„ ', '9í˜¸ì„ '], 'major_stations': ['ì ì‹¤', 'ì†¡íŒŒ', 'ê°€ë½ì‹œì¥']},
        'ë§ˆí¬êµ¬': {'lines': ['2í˜¸ì„ ', '5í˜¸ì„ ', '6í˜¸ì„ '], 'major_stations': ['í™ëŒ€ì…êµ¬', 'í•©ì •', 'ê³µë•']},
        'ìš©ì‚°êµ¬': {'lines': ['1í˜¸ì„ ', '4í˜¸ì„ ', '6í˜¸ì„ '], 'major_stations': ['ìš©ì‚°', 'ì´ì´Œ', 'ì‚¼ê°ì§€']},
        'ì˜ë“±í¬êµ¬': {'lines': ['1í˜¸ì„ ', '5í˜¸ì„ ', '9í˜¸ì„ '], 'major_stations': ['ì˜ë“±í¬êµ¬ì²­', 'ì—¬ì˜ë„', 'ë‹¹ì‚°']},
        'ì„±ë™êµ¬': {'lines': ['2í˜¸ì„ ', '5í˜¸ì„ '], 'major_stations': ['ì„±ìˆ˜', 'ì™•ì‹­ë¦¬', 'ê¸ˆí˜¸']},
        'ì„œëŒ€ë¬¸êµ¬': {'lines': ['2í˜¸ì„ ', '3í˜¸ì„ ', '6í˜¸ì„ '], 'major_stations': ['í™ëŒ€ì…êµ¬', 'ì‹ ì´Œ', 'ì¶©ì •ë¡œ']},
        
        # 3ì : ë³´í†µ ì ‘ê·¼ì„± (1-2ê°œ ë…¸ì„ )
        'ë™ì‘êµ¬': {'lines': ['4í˜¸ì„ ', '7í˜¸ì„ ', '9í˜¸ì„ '], 'major_stations': ['ì‚¬ë‹¹', 'ë…¸ëŸ‰ì§„']},
        'ê´€ì•…êµ¬': {'lines': ['2í˜¸ì„ '], 'major_stations': ['ì‹ ë¦¼', 'ë´‰ì²œ']},
        'ì–‘ì²œêµ¬': {'lines': ['5í˜¸ì„ '], 'major_stations': ['ëª©ë™', 'ì–‘í‰']},
        'êµ¬ë¡œêµ¬': {'lines': ['1í˜¸ì„ ', '2í˜¸ì„ '], 'major_stations': ['êµ¬ë¡œ', 'ì‹ ë„ë¦¼']},
        'ê¸ˆì²œêµ¬': {'lines': ['1í˜¸ì„ '], 'major_stations': ['ë…ì‚°', 'ê°€ì‚°ë””ì§€í„¸ë‹¨ì§€']},
        'ë™ëŒ€ë¬¸êµ¬': {'lines': ['1í˜¸ì„ ', '4í˜¸ì„ '], 'major_stations': ['ë™ëŒ€ë¬¸', 'ì²­ëŸ‰ë¦¬']},
        'ì„±ë¶êµ¬': {'lines': ['4í˜¸ì„ ', '6í˜¸ì„ '], 'major_stations': ['í•œì„±ëŒ€ì…êµ¬', 'ê¸¸ìŒ']},
        'ê´‘ì§„êµ¬': {'lines': ['2í˜¸ì„ ', '5í˜¸ì„ '], 'major_stations': ['ê±´ëŒ€ì…êµ¬', 'ê´‘ë‚˜ë£¨']},
        'ì¤‘ë‘êµ¬': {'lines': ['1í˜¸ì„ ', '7í˜¸ì„ '], 'major_stations': ['ìƒë´‰', 'ë©´ëª©']},
        'ê°•ë¶êµ¬': {'lines': ['4í˜¸ì„ '], 'major_stations': ['ìˆ˜ìœ ', 'ë¯¸ì•„']},
        'ë„ë´‰êµ¬': {'lines': ['1í˜¸ì„ ', '4í˜¸ì„ ', '7í˜¸ì„ '], 'major_stations': ['ë„ë´‰ì‚°', 'ì°½ë™']},
        'ë…¸ì›êµ¬': {'lines': ['4í˜¸ì„ ', '7í˜¸ì„ '], 'major_stations': ['ë…¸ì›', 'ì¤‘ê³„']},
        'ì€í‰êµ¬': {'lines': ['3í˜¸ì„ ', '6í˜¸ì„ '], 'major_stations': ['ì—°ì‹ ë‚´', 'êµ¬íŒŒë°œ']},
        
        # 2ì : ê¸°ë³¸ ì ‘ê·¼ì„± (ì™¸ê³½, ì œí•œì  ë…¸ì„ )
        'ê°•ì„œêµ¬': {'lines': ['5í˜¸ì„ ', '9í˜¸ì„ '], 'major_stations': ['ê¹€í¬ê³µí•­', 'ë°œì‚°']},
        'ê°•ë™êµ¬': {'lines': ['5í˜¸ì„ '], 'major_stations': ['ê°•ë™', 'ì²œí˜¸']},
    }'''

    subway_score_mapping = {
        # 5ì : ìµœê³  ì ‘ê·¼ì„± (4ê°œ ì´ìƒ ë…¸ì„ , ì£¼ìš” í™˜ìŠ¹ì—­ ë°€ì§‘, CBD ë˜ëŠ” ê°•ë‚¨ê¶Œ)
        'ê°•ë‚¨êµ¬': 5, 'ì„œì´ˆêµ¬': 5, 'ì¤‘êµ¬': 5, 'ì¢…ë¡œêµ¬': 5,
        
        # 4ì : ìš°ìˆ˜ ì ‘ê·¼ì„± (2-3ê°œ ì£¼ìš” ë…¸ì„ , í™˜ìŠ¹ì—­ ì¡´ì¬)
        'ì†¡íŒŒêµ¬': 4, 'ë§ˆí¬êµ¬': 4, 'ìš©ì‚°êµ¬': 4, 'ì˜ë“±í¬êµ¬': 4, 
        'ì„±ë™êµ¬': 4, 'ì„œëŒ€ë¬¸êµ¬': 4,
        
        # 3ì : ë³´í†µ ì ‘ê·¼ì„± (1-2ê°œ ë…¸ì„ , ì¼ë°˜ ì—­ì„¸ê¶Œ)
        'ë™ì‘êµ¬': 3, 'ê´€ì•…êµ¬': 3, 'ì–‘ì²œêµ¬': 3, 'êµ¬ë¡œêµ¬': 3, 
        'ê¸ˆì²œêµ¬': 3, 'ë™ëŒ€ë¬¸êµ¬': 3, 'ì„±ë¶êµ¬': 3, 'ê´‘ì§„êµ¬': 3, 
        'ì¤‘ë‘êµ¬': 3, 'ê°•ë¶êµ¬': 3, 'ë„ë´‰êµ¬': 3, 'ë…¸ì›êµ¬': 3, 'ì€í‰êµ¬': 3,
        
        # 2ì : ê¸°ë³¸ ì ‘ê·¼ì„± (ì™¸ê³½ ì§€ì—­, ì œí•œì  ë…¸ì„ )
        'ê°•ì„œêµ¬': 2, 'ê°•ë™êµ¬': 2,
    }
    
    def get_subway_score_by_gu(gu_name):
        return subway_score_mapping.get(gu_name, 2)
    
    # ì§€í•˜ì²  ì ìˆ˜ ì ìš©
    train_data.loc[:, 'SUBWAY_SCORE'] = train_data['CGG_NM'].apply(get_subway_score_by_gu)
    predict_data.loc[:, 'SUBWAY_SCORE'] = predict_data['CGG_NM'].apply(get_subway_score_by_gu)
    
    # ì§€í•˜ì²  ì ìˆ˜ ë¶„í¬
    subway_dist = train_data['SUBWAY_SCORE'].value_counts().sort_index()
    print(f"   ì§€í•˜ì²  ì ‘ê·¼ì„± ì ìˆ˜ ë¶„í¬ (í•™ìŠµ ë°ì´í„°):")
    for score, count in subway_dist.items():
        pct = count / len(train_data) * 100
        print(f"   {score}ì : {count:,}ê±´ ({pct:.1f}%)")
    
    
    # 6. êµ¬ë³„ êµìœ¡íŠ¹êµ¬ í”„ë¦¬ë¯¸ì—„
    print("\n7ï¸âƒ£ êµ¬ë³„ êµìœ¡íŠ¹êµ¬ í”„ë¦¬ë¯¸ì—„")
    
    # ğŸ“š êµìœ¡íŠ¹êµ¬ í”„ë¦¬ë¯¸ì—„ ì‚°ì • ê·¼ê±°:
    # - ê°•ë‚¨êµ¬: ëŒ€ì¹˜ë™ í•™ì›ê°€, ê°•ë‚¨8í•™êµ°, íŠ¹ëª©ê³  ì§‘ì¤‘ (íœ˜ë¬¸ê³ , ì¤‘ë™ê³  ë“±)
    # - ì„œì´ˆêµ¬: ì„œì´ˆ4ë™ í•™ì›ê°€, ì„œì´ˆê³ , ì„œë¬¸ì—¬ê³  ë“± ëª…ë¬¸ê³  ìœ„ì¹˜
    # - ì†¡íŒŒêµ¬: ì ì‹¤ í•™ì›ê°€, ì†¡íŒŒêµ¬ êµìœ¡í™˜ê²½ ìš°ìˆ˜ (ë°©ì´ì¤‘, ì ì‹ ê³  ë“±)
    # - ì–‘ì²œêµ¬: ëª©ë™ í•™ì›ê°€, ì–‘ì²œêµ¬ êµìœ¡ ì¸í”„ë¼ ë°œë‹¬ (ëª©ë™ê³ , ì–‘ì •ê³  ë“±)  
    # - ë…¸ì›êµ¬: ì¤‘ê³„ë™ í•™ì›ê°€, ë…¸ì›êµ¬ êµìœ¡ì—´ ë†’ìŒ (ìƒëª…ê³ , ì„ ë•ê³  ë“±)
    # â€» ì‹¤ì œ ë¶€ë™ì‚° ì‹œì¥ì—ì„œ í•™êµ° í”„ë¦¬ë¯¸ì—„ì´ ì¸ì •ë˜ëŠ” ì§€ì—­ ê¸°ì¤€

    ''' êµìœ¡íŠ¹êµ¬ ê·¼ê±° ëª…ì‹œ
    êµìœ¡íŠ¹êµ¬ í”„ë¦¬ë¯¸ì—„ ì‚°ì • ê¸°ì¤€:
    - íŠ¹ëª©ê³ , ìì‚¬ê³  ë°€ì§‘ë„
    - ëŒ€í•™ ì§„í•™ë¥  ë° í•™ì›ê°€ ë°œë‹¬ ì •ë„
    - ë¶€ë™ì‚° ì‹œì¥ì—ì„œ ì‹¤ì œ í•™êµ° í”„ë¦¬ë¯¸ì—„ì´ ì¸ì •ë˜ëŠ” ì§€ì—­
    
    êµìœ¡íŠ¹êµ¬ ì •ë³´ (ì‹¤ì œ í•™êµ° ì •ë³´ ê¸°ë°˜)
        'ê°•ë‚¨êµ¬': {'íŠ¹ì§•': 'ëŒ€ì¹˜ë™ í•™ì›ê°€, íŠ¹ëª©ê³  ë‹¤ìˆ˜', 'ì£¼ìš”í•™êµ': ['íœ˜ë¬¸ê³ ', 'ë‹¨ëŒ€ë¶€ê³ ', 'ê°œí¬ê³ ']},
        'ì„œì´ˆêµ¬': {'íŠ¹ì§•': 'ë°˜í¬/ì ì› í•™êµ°, ì„œì´ˆê³  ë“±', 'ì£¼ìš”í•™êµ': ['ì„œì´ˆê³ ', 'ë°˜í¬ê³ ', 'ì ì›ê³ ']},
        'ì†¡íŒŒêµ¬': {'íŠ¹ì§•': 'ì ì‹¤ í•™êµ°, ì‹ ì²œê³  ë“±', 'ì£¼ìš”í•™êµ': ['ì‹ ì²œê³ ', 'ì ì‹ ê³ ', 'ë¬¸ì •ê³ ']},
        'ì–‘ì²œêµ¬': {'íŠ¹ì§•': 'ëª©ë™ í•™ì›ê°€, íŠ¹ëª©ê³  ì§‘ì¤‘', 'ì£¼ìš”í•™êµ': ['ëª©ë™ê³ ', 'ì–‘ì •ê³ ', 'ì‹ ëª©ê³ ']},
        'ë…¸ì›êµ¬': {'íŠ¹ì§•': 'ì¤‘ê³„ë™ í•™ì›ê°€, êµìœ¡ì—´ ë†’ìŒ', 'ì£¼ìš”í•™êµ': ['ìƒê³„ê³ ', 'ë…¸ì›ê³ ', 'ì¤‘ê³„ê³ ']},
        
        # ì¼ë°˜ì§€ì—­ (0ì ) - ë‚˜ë¨¸ì§€ ëª¨ë“  êµ¬  '''
    
    education_premium_mapping = {
        'ê°•ë‚¨êµ¬': 1, 'ì„œì´ˆêµ¬': 1, 'ì†¡íŒŒêµ¬': 1, 'ì–‘ì²œêµ¬': 1, 'ë…¸ì›êµ¬': 1,
        # ë‚˜ë¨¸ì§€ëŠ” 0
    }
    
    def get_education_premium_by_gu(gu_name):
        return education_premium_mapping.get(gu_name, 0)
    
    # êµìœ¡íŠ¹êµ¬ ì ìˆ˜ ì ìš©
    train_data.loc[:, 'EDUCATION_PREMIUM'] = train_data['CGG_NM'].apply(get_education_premium_by_gu)
    predict_data.loc[:, 'EDUCATION_PREMIUM'] = predict_data['CGG_NM'].apply(get_education_premium_by_gu)
    
    # êµìœ¡íŠ¹êµ¬ ë¶„í¬
    edu_dist = train_data['EDUCATION_PREMIUM'].value_counts().sort_index()
    print(f"   êµìœ¡íŠ¹êµ¬ í”„ë¦¬ë¯¸ì—„ ë¶„í¬ (í•™ìŠµ ë°ì´í„°):")
    for premium, count in edu_dist.items():
        pct = count / len(train_data) * 100
        status = "êµìœ¡íŠ¹êµ¬" if premium == 1 else "ì¼ë°˜ì§€ì—­"
        print(f"   {status}: {count:,}ê±´ ({pct:.1f}%)")
    
    # êµìœ¡íŠ¹êµ¬ë³„ í‰ê·  ê°€ê²© ë¹„êµ (í•™ìŠµ ë°ì´í„°ë§Œ)
    edu_price_comparison = train_data.groupby('EDUCATION_PREMIUM')['PRICE'].agg(['mean', 'count'])
    print(f"\n   êµìœ¡íŠ¹êµ¬ë³„ í‰ê·  ê°€ê²© (í•™ìŠµ ë°ì´í„°):")
    for premium, stats in edu_price_comparison.iterrows():
        status = "êµìœ¡íŠ¹êµ¬" if premium == 1 else "ì¼ë°˜ì§€ì—­"
        print(f"   {status}: {stats['mean']:,.0f}ë§Œì› ({stats['count']:,}ê±´)")
    
    if len(edu_price_comparison) == 2:
        premium_ratio = edu_price_comparison.loc[1, 'mean'] / edu_price_comparison.loc[0, 'mean']
        print(f"   ğŸ“š êµìœ¡íŠ¹êµ¬ í”„ë¦¬ë¯¸ì—„: {premium_ratio:.2f}ë°° (+{(premium_ratio-1)*100:.1f}%)")
    
    # 7. êµ¬ë³„ Label Encoding (í•µì‹¬! í•™ìŠµ ë°ì´í„°ë§Œ ì‚¬ìš©)
    print("\n8ï¸âƒ£ êµ¬ë³„ Label Encoding (í•™ìŠµ ë°ì´í„° ê¸°ì¤€)")
    
    # í•™ìŠµ ë°ì´í„°ë¡œë§Œ Label Encoder í•™ìŠµ
    label_encoder = LabelEncoder()
    label_encoder.fit(train_data['CGG_NM'])
    
    print(f"   í•™ìŠµëœ êµ¬ ëª©ë¡ ({len(label_encoder.classes_)}ê°œ):")
    for i, gu in enumerate(label_encoder.classes_):
        print(f"   {i:2d}. {gu}")
    
    # ì˜ˆì¸¡ ë°ì´í„°ì— ìƒˆë¡œìš´ êµ¬ê°€ ìˆëŠ”ì§€ í™•ì¸
    predict_gus = set(predict_data['CGG_NM'].unique())
    train_gus = set(train_data['CGG_NM'].unique())
    new_gus = predict_gus - train_gus
    
    if new_gus:
        print(f"\n   âš ï¸  ì˜ˆì¸¡ ë°ì´í„°ì—ë§Œ ìˆëŠ” êµ¬: {new_gus}")
        print(f"   â†’ ì´ëŸ° êµ¬ëŠ” ê°€ì¥ ê°€ê¹Œìš´ êµ¬ì˜ ë¼ë²¨ë¡œ ë§¤í•‘ë©ë‹ˆë‹¤")
    else:
        print(f"\n   âœ… ëª¨ë“  êµ¬ê°€ í•™ìŠµ ë°ì´í„°ì— í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤")
    
    # Label Encoding ì ìš©
    train_data.loc[:, 'CGG_LABEL_ENCODED'] = label_encoder.transform(train_data['CGG_NM'])
    
    # ì˜ˆì¸¡ ë°ì´í„° ì¸ì½”ë”© (ìƒˆë¡œìš´ êµ¬ ì²˜ë¦¬)
    predict_encoded = []
    for gu in predict_data['CGG_NM']:
        if gu in label_encoder.classes_:
            predict_encoded.append(label_encoder.transform([gu])[0])
        else:
            # ìƒˆë¡œìš´ êµ¬ëŠ” ê¸°ë³¸ê°’ 0ìœ¼ë¡œ ì„¤ì •
            predict_encoded.append(0)
            print(f"   âš ï¸  ìƒˆë¡œìš´ êµ¬ '{gu}'ë¥¼ ë¼ë²¨ 0ìœ¼ë¡œ ë§¤í•‘")
    
    predict_data.loc[:, 'CGG_LABEL_ENCODED'] = predict_encoded
    
    # ë¼ë²¨ ë§¤í•‘ ì •ë³´ ì¶œë ¥ (í•™ìŠµ ë°ì´í„° ê¸°ì¤€ ê°€ê²©ìˆœ)
    gu_price_for_sort = train_data.groupby('CGG_NM')['PRICE'].mean().to_dict()
    gu_label_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))
    
    print(f"\n   êµ¬ë³„ Label Encoding ë§¤í•‘ (í•™ìŠµ ë°ì´í„° ê°€ê²©ìˆœ):")
    gu_sorted_by_price = sorted(gu_price_for_sort.items(), key=lambda x: x[1], reverse=True)[:10]
    
    for i, (gu, price) in enumerate(gu_sorted_by_price, 1):
        label = gu_label_mapping[gu]
        print(f"   {i:2d}. {gu} â†’ ë¼ë²¨ {label} (í‰ê·  {price:,.0f}ë§Œì›)")
    
    print(f"\n   ğŸ”¥ í•µì‹¬: í•™ìŠµ ë°ì´í„°(2022-2024)ë¡œë§Œ ì¸ì½”ë”© í•™ìŠµ!")
    print(f"   âœ… 2025 ë°ì´í„°ëŠ” ìˆœìˆ˜ ì˜ˆì¸¡ íƒ€ê²Ÿ")
    print(f"   âœ… ì‹¤ì œ ë°°í¬ í™˜ê²½ê³¼ ë™ì¼í•œ ì¡°ê±´")
    
    # 8. ê°•ë‚¨3êµ¬ í”¼ì²˜
    print("\n9ï¸âƒ£ ê°•ë‚¨3êµ¬ í”¼ì²˜")
    
    # ğŸ™ï¸ ê°•ë‚¨3êµ¬ ì„ ì • ê·¼ê±°:
    # - ê°•ë‚¨êµ¬: ì „í†µì  ë¶€ì´Œ, ìµœê³ ê°€ ì•„íŒŒíŠ¸ ì§‘ì¤‘, ì—…ë¬´ì§€êµ¬(í…Œí—¤ë€ë¡œ) + ìƒì—…ì§€êµ¬(ê°•ë‚¨ì—­)
    # - ì„œì´ˆêµ¬: ë²•ì¡°íƒ€ìš´(ì„œì´ˆë™), ê³ ê¸‰ ì£¼ê±°ì§€(ë°˜í¬ë™), í•œê°• ì¸ì ‘ í”„ë¦¬ë¯¸ì—„
    # - ì†¡íŒŒêµ¬: ì ì‹¤ ì‹ ë„ì‹œ, ë¡¯ë°ì›”ë“œíƒ€ì›Œ, ì˜¬ë¦¼í”½ê³µì›, êµí†µ ìš”ì¶©ì§€
    # â€» ì„œìš¸ ë¶€ë™ì‚° ì‹œì¥ì—ì„œ ì „í†µì ìœ¼ë¡œ ìµœê³  í”„ë¦¬ë¯¸ì—„ì„ ë°›ëŠ” 3ê°œ êµ¬
    
    premium_gus = ['ê°•ë‚¨êµ¬', 'ì„œì´ˆêµ¬', 'ì†¡íŒŒêµ¬']
    train_data.loc[:, 'IS_PREMIUM_GU'] = train_data['CGG_NM'].isin(premium_gus).astype(int)
    predict_data.loc[:, 'IS_PREMIUM_GU'] = predict_data['CGG_NM'].isin(premium_gus).astype(int)
    
    premium_count_train = train_data['IS_PREMIUM_GU'].sum()
    premium_count_predict = predict_data['IS_PREMIUM_GU'].sum()
    
    print(f"   ê°•ë‚¨3êµ¬ ë¶„í¬:")
    print(f"   - í•™ìŠµ ë°ì´í„°: {premium_count_train:,}ê±´ ({premium_count_train/len(train_data)*100:.1f}%)")
    print(f"   - ì˜ˆì¸¡ ë°ì´í„°: {premium_count_predict:,}ê±´ ({premium_count_predict/len(predict_data)*100:.1f}%)")
    
    # 9. ìµœì¢… 8í”¼ì²˜ ì„ íƒ
    print("\nğŸ”Ÿ ìµœì¢… 8í”¼ì²˜ ì„ íƒ")
    
    final_features = [
        'CGG_LABEL_ENCODED',        # 1. êµ¬ë³„ Label Encoding (í•™ìŠµ ë°ì´í„° ê¸°ì¤€)
        'PYEONG',                   # 2. í‰ìˆ˜
        'BUILDING_AGE',             # 3. ê±´ì¶•ë…„ìˆ˜ (2025ë…„ ê¸°ì¤€)
        'FLR',                      # 4. ì¸µìˆ˜
        'BRAND_SCORE',              # 5. ë¸Œëœë“œ ì ìˆ˜ (í•™ìŠµ ë°ì´í„° ê¸°ì¤€)
        'IS_PREMIUM_GU',            # 6. ê°•ë‚¨3êµ¬
        'SUBWAY_SCORE',             # 7. êµ¬ë³„ ì§€í•˜ì²  ì ‘ê·¼ì„±
        'EDUCATION_PREMIUM'         # 8. êµ¬ë³„ êµìœ¡íŠ¹êµ¬
    ]
    
    print(f"   ìµœì¢… í”¼ì²˜ ({len(final_features)}ê°œ):")
    for i, feature in enumerate(final_features, 1):
        print(f"   {i}. {feature}")
    
    print(f"\n   ğŸ”¥ ëª¨ë“  ì¸ì½”ë”©ì´ í•™ìŠµ ë°ì´í„°(2022-2024) ê¸°ì¤€!")
    print(f"   ğŸ¯ 2025 ë°ì´í„°ëŠ” ìˆœìˆ˜ ì˜ˆì¸¡ íƒ€ê²Ÿ!")
    
    # 10. ìµœì¢… ë°ì´í„°ì…‹ ìƒì„±
    print("\n1ï¸âƒ£1ï¸âƒ£ ìµœì¢… ë°ì´í„°ì…‹ ìƒì„±")
    
    X_train = train_data[final_features]
    y_train = train_data['PRICE']
    X_predict = predict_data[final_features]
    y_predict = predict_data['PRICE']  # ì‹¤ì œ ì •ë‹µ (ëª¨ë¸ í‰ê°€ìš©)
    
    print(f"   í•™ìŠµ í”¼ì²˜: {X_train.shape}")
    print(f"   í•™ìŠµ íƒ€ê²Ÿ: {y_train.shape}")
    print(f"   ì˜ˆì¸¡ í”¼ì²˜: {X_predict.shape}")
    print(f"   ì˜ˆì¸¡ ì •ë‹µ: {y_predict.shape} (í‰ê°€ìš©)")
    
    # ê²°ì¸¡ì¹˜ë§Œ ê°„ë‹¨íˆ í™•ì¸
    train_missing = X_train.isnull().sum().sum()
    predict_missing = X_predict.isnull().sum().sum()
    print(f"   ê²°ì¸¡ì¹˜: í•™ìŠµ {train_missing}ê°œ, ì˜ˆì¸¡ {predict_missing}ê°œ")
    
    # 11. íŒŒì¼ ì €ì¥ (ë®ì–´ì“°ê¸°)
    print("\n1ï¸âƒ£2ï¸âƒ£ íŒŒì¼ ì €ì¥ (ë®ì–´ì“°ê¸°)")
    
    # í´ë” ìƒì„±
    os.makedirs('data/processed', exist_ok=True)
    
    # ê³ ì • íŒŒì¼ëª…ìœ¼ë¡œ ë®ì–´ì“°ê¸°
    X_train.to_csv('data/processed/X_train.csv', index=False, encoding='utf-8-sig')
    y_train.to_csv('data/processed/y_train.csv', index=False, encoding='utf-8-sig')
    X_predict.to_csv('data/processed/X_predict.csv', index=False, encoding='utf-8-sig')
    y_predict.to_csv('data/processed/y_predict.csv', index=False, encoding='utf-8-sig')
    
    # ë§¤í•‘ ì •ë³´ ì €ì¥ (í•™ìŠµ ë°ì´í„° ê¸°ì¤€)
    mapping_info = {
        'feature_names': final_features,
        'brand_score_mapping': {brand: get_brand_score(brand) for brand in brand_mapping.keys()},
        'subway_score_mapping': subway_score_mapping,
        'education_premium_mapping': education_premium_mapping,
        'gu_label_mapping': gu_label_mapping,
        'label_encoder_classes': label_encoder.classes_.tolist(),
        'train_period': '2022-2024',
        'predict_period': '2025',
        'outlier_removal': {
            'price_q01': price_q01,
            'price_q99': price_q99, 
            'pyeong_q01': pyeong_q01,
            'pyeong_q99': pyeong_q99
        }
    }
    
    import pickle
    with open('data/processed/mapping_info.pkl', 'wb') as f:
        pickle.dump(mapping_info, f)
    
    print(f"   âœ… data/processed/X_train.csv")
    print(f"   âœ… data/processed/y_train.csv")
    print(f"   âœ… data/processed/X_predict.csv")
    print(f"   âœ… data/processed/y_predict.csv")
    print(f"   âœ… data/processed/mapping_info.pkl")
    print(f"   ğŸ“ íŒŒì¼ ë®ì–´ì“°ê¸° ì™„ë£Œ!")
    
    # 12. ìµœì¢… ìš”ì•½
    print("\n1ï¸âƒ£3ï¸âƒ£ ìµœì¢… ìš”ì•½")
    
    print(f"   ë°ì´í„° ë¶„í• :")
    print(f"   - í•™ìŠµ: {len(train_data):,}ê±´ (2022-2024)")
    print(f"   - ì˜ˆì¸¡: {len(predict_data):,}ê±´ (2025)")
    
    print(f"\n   í•™ìŠµ ë°ì´í„° ê°€ê²© í†µê³„:")
    print(f"   - í‰ê· : {y_train.mean():,.0f}ë§Œì›")
    print(f"   - ì¤‘ì•™ê°’: {y_train.median():,.0f}ë§Œì›")
    print(f"   - ë²”ìœ„: {y_train.min():,.0f} ~ {y_train.max():,.0f}ë§Œì›")
    
    print(f"\n   ì˜ˆì¸¡ ë°ì´í„° ê°€ê²© í†µê³„ (ì •ë‹µ):")
    print(f"   - í‰ê· : {y_predict.mean():,.0f}ë§Œì›")
    print(f"   - ì¤‘ì•™ê°’: {y_predict.median():,.0f}ë§Œì›")
    print(f"   - ë²”ìœ„: {y_predict.min():,.0f} ~ {y_predict.max():,.0f}ë§Œì›")
    
    print("\n" + "=" * 60)
    print("ğŸ‰ 2025 ì„œìš¸ ì•„íŒŒíŠ¸ ê°€ê²© ì˜ˆì¸¡ ì „ì²˜ë¦¬ ì™„ë£Œ!")
    print(f"ğŸ”¥ í•µì‹¬ í¬ì¸íŠ¸:")
    print(f"   ğŸ“š ë°ì´í„° ëˆ„ì¶œ ì™„ì „ ë°©ì§€: í•™ìŠµ ë°ì´í„°ë§Œìœ¼ë¡œ ê·¹ë‹¨ê°’ ê¸°ì¤€ ê³„ì‚°")
    print(f"   ğŸ¯ ë¸Œëœë“œ ê°œì„ : ë¸Œëœë“œì—†ìŒ 1ì  (ì‹¤ì œ í”„ë¦¬ë¯¸ì—„ ë°˜ì˜)")
    print(f"   ğŸ”® ì˜ˆì¸¡ íƒ€ê²Ÿ: 2025 ë°ì´í„° (ìˆœìˆ˜ ì˜ˆì¸¡)")
    print(f"   ğŸ“ íŒŒì¼ ê´€ë¦¬: ë®ì–´ì“°ê¸° ë°©ì‹ìœ¼ë¡œ íš¨ìœ¨ì„± ê·¹ëŒ€í™”")
    print("=" * 60)
    
    return {
        'X_train': X_train,
        'y_train': y_train,
        'X_predict': X_predict,
        'y_predict': y_predict,
        'feature_names': final_features,
        'mapping_info': mapping_info,
        'label_encoder': label_encoder
    }

if __name__ == "__main__":
    print("ğŸ¯ 2025 ì„œìš¸ ì•„íŒŒíŠ¸ ê°€ê²© ì˜ˆì¸¡ ì „ì²˜ë¦¬ (ê°„ë‹¨ ë²„ì „)")
    print("ğŸ“š í•™ìŠµ: 2022-2024 / ğŸ”® ì˜ˆì¸¡: 2025")
    print("ğŸ¯ ì›ë³¸ ë°©ì‹ ìœ ì§€ + ê·¼ê±° ì£¼ì„ ì¶”ê°€!")
    print()
    
    result = preprocessing_for_2025_prediction()
    
    if result:
        print(f"\nğŸŠ ì „ì²˜ë¦¬ ì„±ê³µ! ğŸŠ")
        print(f"ì´ì œ 2025 ê°€ê²© ì˜ˆì¸¡ ëª¨ë¸ì„ í•™ìŠµí•˜ì„¸ìš”:")
        print(f"python model_training_2025_prediction.py")
    else:
        print(f"\nâŒì „ì²˜ë¦¬ ì‹¤íŒ¨")