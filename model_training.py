"""
ì„œìš¸ ì•„íŒŒíŠ¸ ê°€ê²© ì˜ˆì¸¡ - ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ í•™ìŠµ
XGBoost, Random Forest, Linear Regression
"""

import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_absolute_percentage_error, r2_score, mean_squared_error
import xgboost as xgb
import matplotlib.pyplot as plt
import seaborn as sns
import joblib
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')

# í•œê¸€ í°íŠ¸ ì„¤ì •
plt.rcParams['font.family'] = 'Malgun Gothic'
plt.rcParams['axes.unicode_minus'] = False

class ApartmentPriceModeler:
    def __init__(self):
        self.models = {}
        self.scaler = StandardScaler()
        self.results = {}
        
    def load_data(self):
        """ì „ì²˜ë¦¬ëœ ë°ì´í„° ë¡œë“œ"""
        print("ğŸ“‚ ì „ì²˜ë¦¬ëœ ë°ì´í„° ë¡œë“œ")
        print("=" * 40)
        
        try:
            self.X_train = pd.read_csv('data/processed/X_train.csv')
            self.X_test = pd.read_csv('data/processed/X_test.csv')
            self.y_train = pd.read_csv('data/processed/y_train.csv')['THING_AMT']
            self.y_test = pd.read_csv('data/processed/y_test.csv')['THING_AMT']
            
            print(f"âœ… í•™ìŠµ ë°ì´í„°: {self.X_train.shape}")
            print(f"âœ… í…ŒìŠ¤íŠ¸ ë°ì´í„°: {self.X_test.shape}")
            print(f"âœ… í•™ìŠµ íƒ€ê²Ÿ í‰ê· : {self.y_train.mean():,.0f}ë§Œì›")
            print(f"âœ… í…ŒìŠ¤íŠ¸ íƒ€ê²Ÿ í‰ê· : {self.y_test.mean():,.0f}ë§Œì›")
            
            return True
        except Exception as e:
            print(f"âŒ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False
    
    def train_xgboost(self):
        """XGBoost ëª¨ë¸ í•™ìŠµ"""
        print(f"\nğŸš€ XGBoost ëª¨ë¸ í•™ìŠµ")
        print("-" * 30)
        
        # XGBoost ë§¤ê°œë³€ìˆ˜
        xgb_params = {
            'n_estimators': 200,
            'max_depth': 8,
            'learning_rate': 0.1,
            'subsample': 0.8,
            'colsample_bytree': 0.8,
            'random_state': 42,
            'n_jobs': -1
        }
        
        # ëª¨ë¸ ìƒì„± ë° í•™ìŠµ
        self.models['XGBoost'] = xgb.XGBRegressor(**xgb_params)
        
        print("ğŸ”„ XGBoost í•™ìŠµ ì¤‘...")
        self.models['XGBoost'].fit(self.X_train, self.y_train)
        print("âœ… XGBoost í•™ìŠµ ì™„ë£Œ!")
    
    def train_random_forest(self):
        """Random Forest ëª¨ë¸ í•™ìŠµ"""
        print(f"\nğŸŒ² Random Forest ëª¨ë¸ í•™ìŠµ")
        print("-" * 30)
        
        # Random Forest ë§¤ê°œë³€ìˆ˜
        rf_params = {
            'n_estimators': 150,
            'max_depth': 15,
            'min_samples_split': 5,
            'min_samples_leaf': 2,
            'random_state': 42,
            'n_jobs': -1
        }
        
        # ëª¨ë¸ ìƒì„± ë° í•™ìŠµ
        self.models['Random Forest'] = RandomForestRegressor(**rf_params)
        
        print("ğŸ”„ Random Forest í•™ìŠµ ì¤‘...")
        self.models['Random Forest'].fit(self.X_train, self.y_train)
        print("âœ… Random Forest í•™ìŠµ ì™„ë£Œ!")
    
    def train_linear_regression(self):
        """Linear Regression ëª¨ë¸ í•™ìŠµ"""
        print(f"\nğŸ“ˆ Linear Regression ëª¨ë¸ í•™ìŠµ")
        print("-" * 30)
        
        # ì„ í˜•íšŒê·€ë¥¼ ìœ„í•œ ë°ì´í„° ìŠ¤ì¼€ì¼ë§
        print("ğŸ”„ ë°ì´í„° ìŠ¤ì¼€ì¼ë§...")
        X_train_scaled = self.scaler.fit_transform(self.X_train)
        
        # ëª¨ë¸ ìƒì„± ë° í•™ìŠµ
        self.models['Linear Regression'] = LinearRegression()
        
        print("ğŸ”„ Linear Regression í•™ìŠµ ì¤‘...")
        self.models['Linear Regression'].fit(X_train_scaled, self.y_train)
        print("âœ… Linear Regression í•™ìŠµ ì™„ë£Œ!")
    
    def evaluate_model(self, model_name, model):
        """ê°œë³„ ëª¨ë¸ í‰ê°€"""
        print(f"\nğŸ“Š {model_name} ì„±ëŠ¥ í‰ê°€")
        print("-" * 30)
        
        # ì˜ˆì¸¡
        if model_name == 'Linear Regression':
            X_test_scaled = self.scaler.transform(self.X_test)
            X_train_scaled = self.scaler.transform(self.X_train)
            y_pred_test = model.predict(X_test_scaled)
            y_pred_train = model.predict(X_train_scaled)
        else:
            y_pred_test = model.predict(self.X_test)
            y_pred_train = model.predict(self.X_train)
        
        # ìŒìˆ˜ ì˜ˆì¸¡ê°’ ì œê±° (ê°€ê²©ì€ ì–‘ìˆ˜ì—¬ì•¼ í•¨)
        y_pred_test = np.maximum(y_pred_test, 1000)  # ìµœì†Œ 1000ë§Œì›
        y_pred_train = np.maximum(y_pred_train, 1000)
        
        # ë©”íŠ¸ë¦­ ê³„ì‚°
        test_mape = mean_absolute_percentage_error(self.y_test, y_pred_test) * 100
        test_r2 = r2_score(self.y_test, y_pred_test)
        test_rmse = np.sqrt(mean_squared_error(self.y_test, y_pred_test))
        
        train_mape = mean_absolute_percentage_error(self.y_train, y_pred_train) * 100
        train_r2 = r2_score(self.y_train, y_pred_train)
        
        # ê²°ê³¼ ì €ì¥
        self.results[model_name] = {
            'test_mape': test_mape,
            'test_r2': test_r2,
            'test_rmse': test_rmse,
            'train_mape': train_mape,
            'train_r2': train_r2,
            'y_pred_test': y_pred_test,
            'y_pred_train': y_pred_train
        }
        
        # ê²°ê³¼ ì¶œë ¥
        print(f"ğŸ¯ í…ŒìŠ¤íŠ¸ ì„±ëŠ¥:")
        print(f"  MAPE: {test_mape:.2f}%")
        print(f"  RÂ²: {test_r2:.3f}")
        print(f"  RMSE: {test_rmse:,.0f}ë§Œì›")
        
        print(f"ğŸ“š í•™ìŠµ ì„±ëŠ¥:")
        print(f"  MAPE: {train_mape:.2f}%")
        print(f"  RÂ²: {train_r2:.3f}")
        
        # ê³¼ì í•© ì²´í¬
        overfitting = train_mape - test_mape
        if overfitting > 5:
            print(f"âš ï¸ ê³¼ì í•© ê°€ëŠ¥ì„±: {overfitting:.1f}%")
        else:
            print(f"âœ… ì ì ˆí•œ ì¼ë°˜í™”: {overfitting:.1f}%")
        
        return test_mape, test_r2, test_rmse
    
    def compare_models(self):
        """ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ"""
        print(f"\nğŸ† ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ")
        print("=" * 60)
        
        # ë¹„êµ í…Œì´ë¸” ìƒì„±
        comparison_df = pd.DataFrame({
            'Model': list(self.results.keys()),
            'Test_MAPE(%)': [self.results[m]['test_mape'] for m in self.results.keys()],
            'Test_RÂ²': [self.results[m]['test_r2'] for m in self.results.keys()],
            'Test_RMSE(ë§Œì›)': [self.results[m]['test_rmse'] for m in self.results.keys()],
            'Train_MAPE(%)': [self.results[m]['train_mape'] for m in self.results.keys()],
            'Train_RÂ²': [self.results[m]['train_r2'] for m in self.results.keys()]
        })
        
        # ì„±ëŠ¥ìˆœ ì •ë ¬ (MAPE ê¸°ì¤€)
        comparison_df = comparison_df.sort_values('Test_MAPE(%)')
        
        print("ğŸ“Š ì„±ëŠ¥ ë¹„êµí‘œ:")
        print(comparison_df.round(2).to_string(index=False))
        
        # ìµœê³  ì„±ëŠ¥ ëª¨ë¸
        best_model = comparison_df.iloc[0]['Model']
        best_mape = comparison_df.iloc[0]['Test_MAPE(%)']
        best_r2 = comparison_df.iloc[0]['Test_RÂ²']
        
        print(f"\nğŸ¥‡ ìµœê³  ì„±ëŠ¥ ëª¨ë¸: {best_model}")
        print(f"   MAPE: {best_mape:.2f}%")
        print(f"   RÂ²: {best_r2:.3f}")
        
        # ëª©í‘œ ë‹¬ì„± ì—¬ë¶€
        print(f"\nğŸ¯ ëª©í‘œ ë‹¬ì„± ì—¬ë¶€:")
        if best_mape <= 15:
            print(f"âœ… MAPE ëª©í‘œ ë‹¬ì„±: {best_mape:.2f}% â‰¤ 15%")
        else:
            print(f"âŒ MAPE ëª©í‘œ ë¯¸ë‹¬ì„±: {best_mape:.2f}% > 15%")
        
        if best_r2 >= 0.65:
            print(f"âœ… RÂ² ëª©í‘œ ë‹¬ì„±: {best_r2:.3f} â‰¥ 0.65")
        else:
            print(f"âŒ RÂ² ëª©í‘œ ë¯¸ë‹¬ì„±: {best_r2:.3f} < 0.65")
        
        return comparison_df
    
    def analyze_feature_importance(self):
        """í”¼ì²˜ ì¤‘ìš”ë„ ë¶„ì„"""
        print(f"\nğŸ¯ í”¼ì²˜ ì¤‘ìš”ë„ ë¶„ì„")
        print("-" * 40)
        
        # XGBoostì™€ Random Forest í”¼ì²˜ ì¤‘ìš”ë„
        feature_names = self.X_train.columns
        
        importance_df = pd.DataFrame({
            'Feature': feature_names
        })
        
        if 'XGBoost' in self.results:
            xgb_importance = self.models['XGBoost'].feature_importances_
            importance_df['XGBoost'] = xgb_importance
        
        if 'Random Forest' in self.results:
            rf_importance = self.models['Random Forest'].feature_importances_
            importance_df['Random_Forest'] = rf_importance
        
        # í‰ê·  ì¤‘ìš”ë„ ê³„ì‚°
        numeric_cols = [col for col in importance_df.columns if col != 'Feature']
        if numeric_cols:
            importance_df['Average'] = importance_df[numeric_cols].mean(axis=1)
            importance_df = importance_df.sort_values('Average', ascending=False)
        
        print("ğŸ† í”¼ì²˜ ì¤‘ìš”ë„ ìˆœìœ„:")
        for i, (_, row) in enumerate(importance_df.head(10).iterrows(), 1):
            feature = row['Feature']
            avg_importance = row['Average'] if 'Average' in row else 0
            print(f"  {i:2d}. {feature}: {avg_importance:.3f}")
        
        return importance_df
    
    def create_prediction_plots(self):
        """ì˜ˆì¸¡ ê²°ê³¼ ì‹œê°í™”"""
        print(f"\nğŸ“ˆ ì˜ˆì¸¡ ê²°ê³¼ ì‹œê°í™”")
        print("-" * 30)
        
        # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ì˜ ì˜ˆì¸¡ê°’
        best_model = min(self.results.keys(), 
                        key=lambda x: self.results[x]['test_mape'])
        y_pred = self.results[best_model]['y_pred_test']
        
        # 2x2 í”Œë¡¯
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        
        # 1. ì‹¤ì œê°’ vs ì˜ˆì¸¡ê°’ ì‚°ì ë„
        axes[0,0].scatter(self.y_test, y_pred, alpha=0.5, s=20)
        axes[0,0].plot([self.y_test.min(), self.y_test.max()], 
                      [self.y_test.min(), self.y_test.max()], 'r--', lw=2)
        axes[0,0].set_xlabel('ì‹¤ì œê°’ (ë§Œì›)')
        axes[0,0].set_ylabel('ì˜ˆì¸¡ê°’ (ë§Œì›)')
        axes[0,0].set_title(f'{best_model}: ì‹¤ì œê°’ vs ì˜ˆì¸¡ê°’')
        
        # 2. ì”ì°¨ í”Œë¡¯
        residuals = self.y_test - y_pred
        axes[0,1].scatter(y_pred, residuals, alpha=0.5, s=20)
        axes[0,1].axhline(y=0, color='r', linestyle='--')
        axes[0,1].set_xlabel('ì˜ˆì¸¡ê°’ (ë§Œì›)')
        axes[0,1].set_ylabel('ì”ì°¨ (ë§Œì›)')
        axes[0,1].set_title('ì”ì°¨ í”Œë¡¯')
        
        # 3. ëª¨ë¸ë³„ MAPE ë¹„êµ
        models = list(self.results.keys())
        mapes = [self.results[m]['test_mape'] for m in models]
        bars = axes[1,0].bar(range(len(models)), mapes, 
                           color=['gold', 'silver', 'orange'][:len(models)])
        axes[1,0].set_xticks(range(len(models)))
        axes[1,0].set_xticklabels(models, rotation=45)
        axes[1,0].set_ylabel('MAPE (%)')
        axes[1,0].set_title('ëª¨ë¸ë³„ MAPE ë¹„êµ')
        
        # ê°’ í‘œì‹œ
        for bar, mape in zip(bars, mapes):
            height = bar.get_height()
            axes[1,0].text(bar.get_x() + bar.get_width()/2., height + 0.1,
                         f'{mape:.1f}%', ha='center', va='bottom')
        
        # 4. ì˜¤ì°¨ ë¶„í¬ íˆìŠ¤í† ê·¸ë¨
        error_percent = (residuals / self.y_test) * 100
        axes[1,1].hist(error_percent, bins=30, alpha=0.7, color='skyblue')
        axes[1,1].axvline(x=0, color='r', linestyle='--')
        axes[1,1].set_xlabel('ìƒëŒ€ ì˜¤ì°¨ (%)')
        axes[1,1].set_ylabel('ë¹ˆë„')
        axes[1,1].set_title('ì˜ˆì¸¡ ì˜¤ì°¨ ë¶„í¬')
        
        plt.tight_layout()
        plt.show()
        
        # ì˜¤ì°¨ í†µê³„
        print(f"ğŸ“Š ì˜ˆì¸¡ ì˜¤ì°¨ í†µê³„:")
        print(f"  í‰ê·  ì ˆëŒ€ ì˜¤ì°¨: {np.abs(residuals).mean():,.0f}ë§Œì›")
        print(f"  ì˜¤ì°¨ í‘œì¤€í¸ì°¨: {residuals.std():,.0f}ë§Œì›")
        print(f"  Â±20% ë‚´ ì˜ˆì¸¡ ë¹„ìœ¨: {(np.abs(error_percent) <= 20).mean()*100:.1f}%")
        print(f"  Â±10% ë‚´ ì˜ˆì¸¡ ë¹„ìœ¨: {(np.abs(error_percent) <= 10).mean()*100:.1f}%")
    
    def save_models(self):
        """ëª¨ë¸ ì €ì¥"""
        print(f"\nğŸ’¾ ëª¨ë¸ ì €ì¥")
        print("-" * 30)
        
        # ë””ë ‰í† ë¦¬ ìƒì„±
        Path("models").mkdir(exist_ok=True)
        
        # ê° ëª¨ë¸ ì €ì¥
        for name, model in self.models.items():
            filename = f"models/{name.lower().replace(' ', '_')}_model.pkl"
            joblib.dump(model, filename)
            print(f"âœ… {name} ì €ì¥: {filename}")
        
        # ìŠ¤ì¼€ì¼ëŸ¬ ì €ì¥ (Linear Regressionìš©)
        joblib.dump(self.scaler, "models/scaler.pkl")
        print(f"âœ… Scaler ì €ì¥: models/scaler.pkl")
        
        # ê²°ê³¼ ì €ì¥
        results_summary = {}
        for name, result in self.results.items():
            results_summary[name] = {
                'test_mape': result['test_mape'],
                'test_r2': result['test_r2'],
                'test_rmse': result['test_rmse'],
                'train_mape': result['train_mape'],
                'train_r2': result['train_r2']
            }
        
        import json
        with open('models/model_results.json', 'w') as f:
            json.dump(results_summary, f, indent=2)
        print(f"âœ… ê²°ê³¼ ì €ì¥: models/model_results.json")
    
    def run_full_pipeline(self):
        """ì „ì²´ ëª¨ë¸ë§ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
        print("ğŸ¤– ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ í•™ìŠµ íŒŒì´í”„ë¼ì¸ ì‹œì‘")
        print("=" * 60)
        
        # 1. ë°ì´í„° ë¡œë“œ
        if not self.load_data():
            return
        
        # 2. ëª¨ë¸ í•™ìŠµ
        self.train_xgboost()
        self.train_random_forest()
        self.train_linear_regression()
        
        # 3. ëª¨ë¸ í‰ê°€
        for name, model in self.models.items():
            self.evaluate_model(name, model)
        
        # 4. ì„±ëŠ¥ ë¹„êµ
        comparison_df = self.compare_models()
        
        # 5. í”¼ì²˜ ì¤‘ìš”ë„ ë¶„ì„
        importance_df = self.analyze_feature_importance()
        
        # 6. ì‹œê°í™”
        self.create_prediction_plots()
        
        # 7. ëª¨ë¸ ì €ì¥
        self.save_models()
        
        print(f"\nğŸ‰ ëª¨ë¸ë§ ì™„ë£Œ!")
        print("=" * 60)
        print(f"âœ… 3ê°œ ëª¨ë¸ í•™ìŠµ ì™„ë£Œ")
        print(f"âœ… ì„±ëŠ¥ í‰ê°€ ì™„ë£Œ")
        print(f"âœ… í”¼ì²˜ ì¤‘ìš”ë„ ë¶„ì„ ì™„ë£Œ")
        print(f"âœ… ì‹œê°í™” ì™„ë£Œ")
        print(f"âœ… ëª¨ë¸ ì €ì¥ ì™„ë£Œ")
        
        # ìµœì¢… ìš”ì•½
        best_model = comparison_df.iloc[0]['Model']
        best_mape = comparison_df.iloc[0]['Test_MAPE(%)']
        
        print(f"\nğŸ† ìµœì¢… ê²°ê³¼:")
        print(f"  ìµœê³  ì„±ëŠ¥ ëª¨ë¸: {best_model}")
        print(f"  MAPE: {best_mape:.2f}%")
        print(f"  ëª©í‘œ ë‹¬ì„±: {'âœ…' if best_mape <= 15 else 'âŒ'}")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    modeler = ApartmentPriceModeler()
    modeler.run_full_pipeline()

if __name__ == "__main__":
    main()