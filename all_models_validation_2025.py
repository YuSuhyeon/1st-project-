"""
2025 ì„œìš¸ ì•„íŒŒíŠ¸ ê°€ê²© ì˜ˆì¸¡ ì •í™•ë„ ê²€ì¦ (ì „ì²´ ëª¨ë¸ ë¹„êµ)
Random Forest, XGBoost, Linear Regression ì„±ëŠ¥ ë¹„êµ + ìƒì„¸ ë¶„ì„
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import joblib
import pickle
import json
import os
from pathlib import Path
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, mean_absolute_percentage_error
import warnings
warnings.filterwarnings('ignore')

# í•œê¸€ í°íŠ¸ ì„¤ì •
plt.rcParams['font.family'] = 'DejaVu Sans'
plt.rcParams['axes.unicode_minus'] = False

def validate_all_models_2025():
    """ëª¨ë“  ëª¨ë¸ì˜ 2025 ë°ì´í„° ì •í™•ë„ ê²€ì¦ ë° ë¹„êµ"""
    print("ğŸ¯ 2025 ì„œìš¸ ì•„íŒŒíŠ¸ ê°€ê²© ì˜ˆì¸¡ ì •í™•ë„ ê²€ì¦")
    print("ğŸ¤– Random Forest vs XGBoost vs Linear Regression ì„±ëŠ¥ ë¹„êµ")
    print("=" * 60)
    
    # 1. ëª¨ë“  ëª¨ë¸ ë¡œë“œ
    print("1ï¸âƒ£ ëª¨ë“  ëª¨ë¸ ë¡œë“œ")
    
    models = {}
    scalers = {}
    
    # Random Forest ë¡œë“œ
    try:
        models['Random Forest'] = joblib.load('models/random_forest_model.pkl')
        print("   âœ… Random Forest ë¡œë“œ ì„±ê³µ")
    except Exception as e:
        print(f"   âŒ Random Forest ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    # XGBoost ë¡œë“œ
    try:
        models['XGBoost'] = joblib.load('models/xgboost_model.pkl')
        print("   âœ… XGBoost ë¡œë“œ ì„±ê³µ")
    except Exception as e:
        print(f"   âŒ XGBoost ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    # Linear Regression ë¡œë“œ
    try:
        models['Linear Regression'] = joblib.load('models/linear_regression_model.pkl')
        scalers['Linear Regression'] = joblib.load('models/scaler.pkl')
        print("   âœ… Linear Regression + Scaler ë¡œë“œ ì„±ê³µ")
    except Exception as e:
        print(f"   âŒ Linear Regression ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    if not models:
        print("   âŒ ë¡œë“œëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤!")
        print("   ë¨¼ì € ëª¨ë¸ í•™ìŠµì„ ì‹¤í–‰í•˜ì„¸ìš”: python model_training_2025_prediction.py")
        return False
    
    print(f"   ğŸ“Š ì´ {len(models)}ê°œ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
    
    # 2. 2025 í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ
    print("\n2ï¸âƒ£ 2025 í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ")
    
    try:
        X_predict = pd.read_csv('data/processed/X_predict.csv')
        y_predict = pd.read_csv('data/processed/y_predict.csv').squeeze()
        print(f"   âœ… 2025 ì˜ˆì¸¡ ë°ì´í„°: {X_predict.shape}")
        print(f"   âœ… 2025 ì‹¤ì œ ê°€ê²©: {len(y_predict)}ê°œ")
        
        # ê¸°ë³¸ í†µê³„
        print(f"\n   ğŸ“Š 2025ë…„ ì‹¤ì œ ê°€ê²© í†µê³„:")
        print(f"      í‰ê· : {y_predict.mean():,.0f}ë§Œì›")
        print(f"      ì¤‘ì•™ê°’: {y_predict.median():,.0f}ë§Œì›")
        print(f"      ë²”ìœ„: {y_predict.min():,.0f} ~ {y_predict.max():,.0f}ë§Œì›")
        
    except Exception as e:
        print(f"   âŒ í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
        print("   ë¨¼ì € ì „ì²˜ë¦¬ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”: python preprocessing_for_2025_prediction.py")
        return False
    
    # 3. ë§¤í•‘ ì •ë³´ ë¡œë“œ
    print("\n3ï¸âƒ£ ë§¤í•‘ ì •ë³´ ë¡œë“œ")
    
    try:
        with open('data/processed/mapping_info.pkl', 'rb') as f:
            mapping_info = pickle.load(f)
        print("   âœ… ë§¤í•‘ ì •ë³´ ë¡œë“œ ì„±ê³µ")
    except:
        print("   âš ï¸ ë§¤í•‘ ì •ë³´ ì—†ìŒ, ê¸°ë³¸ê°’ ì‚¬ìš©")
        mapping_info = create_default_mapping()
    
    # 4. ëª¨ë“  ëª¨ë¸ë¡œ ì˜ˆì¸¡ ìˆ˜í–‰
    print("\n4ï¸âƒ£ ëª¨ë“  ëª¨ë¸ ì˜ˆì¸¡ ìˆ˜í–‰")
    
    predictions = {}
    
    for model_name, model in models.items():
        try:
            print(f"   ğŸ”® {model_name} ì˜ˆì¸¡ ì¤‘...")
            
            if model_name == 'Linear Regression':
                # Linear Regression: ìŠ¤ì¼€ì¼ë§ ì ìš©
                X_scaled = scalers[model_name].transform(X_predict)
                pred = model.predict(X_scaled)
            else:
                # Random Forest, XGBoost: ì§ì ‘ ì˜ˆì¸¡
                pred = model.predict(X_predict)
            
            # ìµœì†Œê°’ ë³´ì • (1ì–µì› ì´ìƒ)
            pred = np.maximum(pred, 10000)
            predictions[model_name] = pred
            
            print(f"      âœ… ì™„ë£Œ: í‰ê·  {pred.mean():,.0f}ë§Œì›")
            
        except Exception as e:
            print(f"      âŒ {model_name} ì˜ˆì¸¡ ì‹¤íŒ¨: {e}")
    
    if not predictions:
        print("   âŒ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•œ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤!")
        return False
    
    # 5. ëª¨ë“  ëª¨ë¸ ì„±ëŠ¥ ì§€í‘œ ê³„ì‚°
    print("\n5ï¸âƒ£ ëª¨ë“  ëª¨ë¸ ì„±ëŠ¥ ì§€í‘œ ê³„ì‚°")
    
    results = {}
    
    for model_name, pred in predictions.items():
        # ê¸°ë³¸ ì„±ëŠ¥ ì§€í‘œ
        mae = mean_absolute_error(y_predict, pred)
        rmse = np.sqrt(mean_squared_error(y_predict, pred))
        mape = mean_absolute_percentage_error(y_predict, pred) * 100
        r2 = r2_score(y_predict, pred)
        
        # ì˜¤ì°¨ ê³„ì‚°
        absolute_errors = np.abs(y_predict - pred)
        percentage_errors = (absolute_errors / y_predict) * 100
        
        # ì •í™•ë„ êµ¬ê°„
        accuracy_ranges = {
            'within_10pct': (percentage_errors <= 10).mean() * 100,
            'within_20pct': (percentage_errors <= 20).mean() * 100,
            'within_30pct': (percentage_errors <= 30).mean() * 100,
            'within_2ì–µ': (absolute_errors <= 20000).mean() * 100,
            'over_50pct': (percentage_errors > 50).sum()
        }
        
        results[model_name] = {
            'MAE': mae,
            'RMSE': rmse,
            'MAPE': mape,
            'RÂ²': r2,
            'accuracy_ranges': accuracy_ranges,
            'predictions': pred,
            'absolute_errors': absolute_errors,
            'percentage_errors': percentage_errors
        }
        
        print(f"   ğŸ“Š {model_name}:")
        print(f"      MAE: {mae:,.0f}ë§Œì›")
        print(f"      RMSE: {rmse:,.0f}ë§Œì›")
        print(f"      MAPE: {mape:.2f}%")
        print(f"      RÂ²: {r2:.3f}")
        print(f"      Â±20% ì´ë‚´: {accuracy_ranges['within_20pct']:.1f}%")
    
    # 6. ëª¨ë¸ ìˆœìœ„ ë° ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì„ ì •
    print("\n6ï¸âƒ£ ëª¨ë¸ ì„±ëŠ¥ ìˆœìœ„")
    
    # MAE ê¸°ì¤€ ìˆœìœ„
    mae_ranking = sorted(results.items(), key=lambda x: x[1]['MAE'])
    print(f"   ğŸ† MAE ê¸°ì¤€ ìˆœìœ„:")
    for i, (model_name, metrics) in enumerate(mae_ranking, 1):
        print(f"      {i}ìœ„. {model_name}: {metrics['MAE']:,.0f}ë§Œì›")
    
    # RÂ² ê¸°ì¤€ ìˆœìœ„
    r2_ranking = sorted(results.items(), key=lambda x: x[1]['RÂ²'], reverse=True)
    print(f"\n   ğŸ† RÂ² ê¸°ì¤€ ìˆœìœ„:")
    for i, (model_name, metrics) in enumerate(r2_ranking, 1):
        print(f"      {i}ìœ„. {model_name}: {metrics['RÂ²']:.3f}")
    
    # Â±20% ì •í™•ë„ ê¸°ì¤€ ìˆœìœ„
    accuracy_ranking = sorted(results.items(), key=lambda x: x[1]['accuracy_ranges']['within_20pct'], reverse=True)
    print(f"\n   ğŸ† Â±20% ì •í™•ë„ ê¸°ì¤€ ìˆœìœ„:")
    for i, (model_name, metrics) in enumerate(accuracy_ranking, 1):
        print(f"      {i}ìœ„. {model_name}: {metrics['accuracy_ranges']['within_20pct']:.1f}%")
    
    # ì¢…í•© ìµœê³  ëª¨ë¸ (MAEê°€ ê°€ì¥ ë‚®ì€ ëª¨ë¸)
    best_model = mae_ranking[0][0]
    print(f"\n   ğŸ¥‡ ì¢…í•© ìµœê³  ëª¨ë¸: {best_model}")
    
    # 7. êµ¬ë³„ ìƒì„¸ ë¶„ì„ (ìµœê³  ëª¨ë¸ ê¸°ì¤€)
    print(f"\n7ï¸âƒ£ êµ¬ë³„ ìƒì„¸ ë¶„ì„ ({best_model} ê¸°ì¤€)")
    
    # êµ¬ë³„ ì—­ë§¤í•‘
    gu_reverse_mapping = {v: k for k, v in mapping_info.get('gu_label_mapping', {}).items()}
    gu_names = [gu_reverse_mapping.get(x, f'êµ¬{x}') for x in X_predict['CGG_LABEL_ENCODED']]
    
    # ê²°ê³¼ DataFrame ìƒì„±
    results_df = pd.DataFrame({
        'ì‹¤ì œê°€ê²©': y_predict,
        'êµ¬': gu_names,
        'í‰ìˆ˜': X_predict['PYEONG'],
        'ê±´ì¶•ë…„ìˆ˜': X_predict['BUILDING_AGE'],
        'ì¸µìˆ˜': X_predict['FLR'],
        'ë¸Œëœë“œì ìˆ˜': X_predict['BRAND_SCORE'],
        'ê°•ë‚¨3êµ¬': X_predict['IS_PREMIUM_GU'],
        'ì§€í•˜ì² ì ìˆ˜': X_predict['SUBWAY_SCORE'],
        'êµìœ¡íŠ¹êµ¬': X_predict['EDUCATION_PREMIUM']
    })
    
    # ëª¨ë“  ëª¨ë¸ì˜ ì˜ˆì¸¡ê°’ê³¼ ì˜¤ì°¨ ì¶”ê°€
    for model_name, metrics in results.items():
        results_df[f'ì˜ˆì¸¡_{model_name}'] = metrics['predictions']
        results_df[f'ì˜¤ì°¨_{model_name}'] = metrics['absolute_errors']
        results_df[f'ì˜¤ì°¨ìœ¨_{model_name}'] = metrics['percentage_errors']
    
    # êµ¬ë³„ ì„±ëŠ¥ ë¶„ì„ (ìµœê³  ëª¨ë¸ ê¸°ì¤€)
    district_analysis = results_df.groupby('êµ¬').agg({
        'ì‹¤ì œê°€ê²©': ['count', 'mean'],
        f'ì˜¤ì°¨_{best_model}': 'mean',
        f'ì˜¤ì°¨ìœ¨_{best_model}': 'mean'
    }).round(1)
    
    district_analysis.columns = ['ê±°ë˜ìˆ˜', 'í‰ê· ê°€ê²©', 'í‰ê· ì˜¤ì°¨', 'í‰ê· ì˜¤ì°¨ìœ¨']
    district_analysis = district_analysis.sort_values('í‰ê· ì˜¤ì°¨ìœ¨')
    
    print(f"   ğŸ† ì˜ˆì¸¡ ì •í™•ë„ TOP 5 êµ¬:")
    print(district_analysis.head().to_string())
    
    print(f"\n   ğŸ“‰ ì˜ˆì¸¡ ì •í™•ë„ BOTTOM 5 êµ¬:")
    print(district_analysis.tail().to_string())
    
    # 8. ê°€ê²©ëŒ€ë³„ ì„±ëŠ¥ ë¶„ì„
    print("\n8ï¸âƒ£ ê°€ê²©ëŒ€ë³„ ì„±ëŠ¥ ë¶„ì„")
    
    # ê°€ê²©ëŒ€ ë¶„ë¥˜
    results_df['ê°€ê²©ëŒ€'] = pd.cut(results_df['ì‹¤ì œê°€ê²©'], 
                                bins=[0, 50000, 100000, 150000, 200000, float('inf')],
                                labels=['5ì–µì´í•˜', '5-10ì–µ', '10-15ì–µ', '15-20ì–µ', '20ì–µì´ˆê³¼'])
    
    price_analysis = results_df.groupby('ê°€ê²©ëŒ€').agg({
        'ì‹¤ì œê°€ê²©': ['count', 'mean'],
        f'ì˜¤ì°¨_{best_model}': 'mean',
        f'ì˜¤ì°¨ìœ¨_{best_model}': 'mean'
    }).round(1)
    
    price_analysis.columns = ['ê±°ë˜ìˆ˜', 'í‰ê· ê°€ê²©', 'í‰ê· ì˜¤ì°¨', 'í‰ê· ì˜¤ì°¨ìœ¨']
    print(price_analysis.to_string())
    
    # 9. ëª¨ë¸ê°„ ì˜ˆì¸¡ ì¼ì¹˜ë„ ë¶„ì„
    print("\n9ï¸âƒ£ ëª¨ë¸ê°„ ì˜ˆì¸¡ ì¼ì¹˜ë„ ë¶„ì„")
    
    if len(predictions) >= 2:
        model_names = list(predictions.keys())
        print(f"   ğŸ¤ ëª¨ë¸ê°„ ìƒê´€ê´€ê³„:")
        
        for i in range(len(model_names)):
            for j in range(i+1, len(model_names)):
                model1, model2 = model_names[i], model_names[j]
                pred1, pred2 = predictions[model1], predictions[model2]
                
                correlation = np.corrcoef(pred1, pred2)[0, 1]
                avg_diff = np.mean(np.abs(pred1 - pred2))
                
                print(f"      {model1} vs {model2}:")
                print(f"        ìƒê´€ê³„ìˆ˜: {correlation:.3f}")
                print(f"        í‰ê·  ì°¨ì´: {avg_diff:,.0f}ë§Œì›")
    
    # 10. ì‹œê°í™” ìƒì„±
    print("\nğŸ”Ÿ ì‹œê°í™” ìƒì„±")
    
    # í´ë” ìƒì„±
    os.makedirs('plots', exist_ok=True)
    
    # 10-1. ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ ì°¨íŠ¸
    fig, axes = plt.subplots(2, 2, figsize=(15, 12))
    
    model_names = list(results.keys())
    colors = ['#3498db', '#2ecc71', '#e74c3c'][:len(model_names)]
    
    # MAE ë¹„êµ
    mae_values = [results[model]['MAE'] for model in model_names]
    bars1 = axes[0,0].bar(model_names, mae_values, color=colors)
    axes[0,0].set_title('MAE Comparison (Lower is Better)')
    axes[0,0].set_ylabel('MAE (ë§Œì›)')
    axes[0,0].grid(True, alpha=0.3)
    for i, v in enumerate(mae_values):
        axes[0,0].text(i, v + max(mae_values)*0.01, f'{v:,.0f}', ha='center', va='bottom')
    
    # RÂ² ë¹„êµ
    r2_values = [results[model]['RÂ²'] for model in model_names]
    bars2 = axes[0,1].bar(model_names, r2_values, color=colors)
    axes[0,1].set_title('RÂ² Comparison (Higher is Better)')
    axes[0,1].set_ylabel('RÂ²')
    axes[0,1].grid(True, alpha=0.3)
    for i, v in enumerate(r2_values):
        axes[0,1].text(i, v + max(r2_values)*0.01, f'{v:.3f}', ha='center', va='bottom')
    
    # MAPE ë¹„êµ
    mape_values = [results[model]['MAPE'] for model in model_names]
    bars3 = axes[1,0].bar(model_names, mape_values, color=colors)
    axes[1,0].set_title('MAPE Comparison (Lower is Better)')
    axes[1,0].set_ylabel('MAPE (%)')
    axes[1,0].grid(True, alpha=0.3)
    for i, v in enumerate(mape_values):
        axes[1,0].text(i, v + max(mape_values)*0.01, f'{v:.1f}%', ha='center', va='bottom')
    
    # Â±20% ì •í™•ë„ ë¹„êµ
    accuracy_values = [results[model]['accuracy_ranges']['within_20pct'] for model in model_names]
    bars4 = axes[1,1].bar(model_names, accuracy_values, color=colors)
    axes[1,1].set_title('Â±20% Accuracy (Higher is Better)')
    axes[1,1].set_ylabel('Accuracy (%)')
    axes[1,1].grid(True, alpha=0.3)
    for i, v in enumerate(accuracy_values):
        axes[1,1].text(i, v + max(accuracy_values)*0.01, f'{v:.1f}%', ha='center', va='bottom')
    
    plt.tight_layout()
    performance_plot_path = 'plots/all_models_performance_comparison_2025.png'
    plt.savefig(performance_plot_path, dpi=300, bbox_inches='tight')
    plt.close()
    print(f"   âœ… ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ: {performance_plot_path}")
    
    # 10-2. ì˜ˆì¸¡ vs ì‹¤ì œ ì‚°ì ë„ (ëª¨ë“  ëª¨ë¸)
    fig, axes = plt.subplots(1, len(model_names), figsize=(5*len(model_names), 5))
    if len(model_names) == 1:
        axes = [axes]
    
    for i, model_name in enumerate(model_names):
        pred = predictions[model_name]
        r2 = results[model_name]['RÂ²']
        mae = results[model_name]['MAE']
        
        axes[i].scatter(y_predict, pred, alpha=0.5, s=1, color=colors[i])
        axes[i].plot([y_predict.min(), y_predict.max()], 
                    [y_predict.min(), y_predict.max()], 'r--', lw=2)
        axes[i].set_xlabel('Actual Price (ë§Œì›)')
        axes[i].set_ylabel('Predicted Price (ë§Œì›)')
        axes[i].set_title(f'{model_name}\nRÂ² = {r2:.3f}, MAE = {mae:,.0f}')
        axes[i].grid(True, alpha=0.3)
    
    plt.tight_layout()
    scatter_plot_path = 'plots/prediction_vs_actual_all_models_2025.png'
    plt.savefig(scatter_plot_path, dpi=300, bbox_inches='tight')
    plt.close()
    print(f"   âœ… ì˜ˆì¸¡ vs ì‹¤ì œ ì‚°ì ë„: {scatter_plot_path}")
    
    # 11. ê²°ê³¼ ì €ì¥
    print("\n1ï¸âƒ£1ï¸âƒ£ ê²°ê³¼ ì €ì¥")
    
    # í´ë” ìƒì„±
    for folder in ['results', 'reports']:
        os.makedirs(folder, exist_ok=True)
    
    # ì „ì²´ ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥
    results_path = 'results/all_models_prediction_validation_2025.csv'
    results_df.to_csv(results_path, index=False, encoding='utf-8-sig')
    print(f"   âœ… ì „ì²´ ì˜ˆì¸¡ ê²°ê³¼: {results_path}")
    
    # ëª¨ë¸ ì„±ëŠ¥ ìš”ì•½ ì €ì¥
    performance_summary = {}
    for model_name, metrics in results.items():
        performance_summary[model_name] = {
            'MAE': float(metrics['MAE']),
            'RMSE': float(metrics['RMSE']),
            'MAPE': float(metrics['MAPE']),
            'RÂ²': float(metrics['RÂ²']),
            'within_20pct': float(metrics['accuracy_ranges']['within_20pct']),
            'over_50pct_errors': int(metrics['accuracy_ranges']['over_50pct'])
        }
    
    summary_path = 'results/all_models_performance_summary_2025.json'
    with open(summary_path, 'w', encoding='utf-8') as f:
        json.dump(performance_summary, f, indent=2, ensure_ascii=False)
    print(f"   âœ… ì„±ëŠ¥ ìš”ì•½: {summary_path}")
    
    # 12. ìµœì¢… ë³´ê³ ì„œ ìƒì„±
    print("\n1ï¸âƒ£2ï¸âƒ£ ìµœì¢… ë³´ê³ ì„œ ìƒì„±")
    
    # ì‹¤ìš©ì„± í‰ê°€
    best_accuracy = results[best_model]['accuracy_ranges']['within_20pct']
    if best_accuracy >= 80:
        practical_level = "ë§¤ìš° ì‹¤ìš©ì "
        practical_emoji = "ğŸš€"
    elif best_accuracy >= 70:
        practical_level = "ì‹¤ìš©ì "
        practical_emoji = "âœ…"
    elif best_accuracy >= 60:
        practical_level = "ë³´í†µ"
        practical_emoji = "âš ï¸"
    else:
        practical_level = "ê°œì„  í•„ìš”"
        practical_emoji = "âŒ"
    
    report = f"""
=================================================================
ğŸ¯ 2025 ì„œìš¸ ì•„íŒŒíŠ¸ ê°€ê²© ì˜ˆì¸¡ ëª¨ë¸ ì „ì²´ ì„±ëŠ¥ ê²€ì¦ ë³´ê³ ì„œ
=================================================================

ğŸ“… ê²€ì¦ ë‚ ì§œ: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}
ğŸ“Š ê²€ì¦ ë°ì´í„°: {len(results_df):,}ê±´ (2025ë…„ ì‹¤ì œ ê±°ë˜)
ğŸ¤– ê²€ì¦ ëª¨ë¸: {', '.join(model_names)}

ğŸ† ì¢…í•© ìµœê³  ëª¨ë¸: {best_model}

ğŸ“Š ëª¨ë¸ë³„ ì„±ëŠ¥ ìš”ì•½:
"""
    
    for model_name, metrics in results.items():
        symbol = "ğŸ¥‡" if model_name == best_model else "ğŸ¥ˆ" if model_name == mae_ranking[1][0] else "ğŸ¥‰"
        report += f"""
{symbol} {model_name}:
   - MAE: {metrics['MAE']:,.0f}ë§Œì›
   - RMSE: {metrics['RMSE']:,.0f}ë§Œì›
   - MAPE: {metrics['MAPE']:.2f}%
   - RÂ²: {metrics['RÂ²']:.3f} ({metrics['RÂ²']*100:.1f}% ì„¤ëª…ë ¥)
   - Â±20% ì´ë‚´: {metrics['accuracy_ranges']['within_20pct']:.1f}%
   - ê·¹ë‹¨ì˜¤ì°¨(50%ì´ˆê³¼): {metrics['accuracy_ranges']['over_50pct']}ê±´
"""
    
    report += f"""
{practical_emoji} ì‹¤ìš©ì„± í‰ê°€: {practical_level}
   (ìµœê³  ëª¨ë¸ Â±20% ì´ë‚´ ì˜ˆì¸¡ë¥ : {best_accuracy:.1f}%)

ğŸ˜ï¸ êµ¬ë³„ ì„±ëŠ¥ TOP 3 ({best_model} ê¸°ì¤€):
"""
    
    for i, (district, row) in enumerate(district_analysis.head(3).iterrows(), 1):
        report += f"   {i}. {district}: {row['í‰ê· ì˜¤ì°¨ìœ¨']:.1f}% (ê±°ë˜ìˆ˜: {row['ê±°ë˜ìˆ˜']:.0f})\n"
    
    report += f"""
ğŸ’° ê°€ê²©ëŒ€ë³„ ì„±ëŠ¥ ({best_model} ê¸°ì¤€):
"""
    for price_range, row in price_analysis.iterrows():
        report += f"   - {price_range}: {row['í‰ê· ì˜¤ì°¨ìœ¨']:.1f}% (ê±°ë˜ìˆ˜: {row['ê±°ë˜ìˆ˜']:.0f})\n"
    
    if len(model_names) >= 2:
        report += f"""
ğŸ¤ ëª¨ë¸ê°„ ì¼ì¹˜ë„:
"""
        for i in range(len(model_names)):
            for j in range(i+1, len(model_names)):
                model1, model2 = model_names[i], model_names[j]
                pred1, pred2 = predictions[model1], predictions[model2]
                correlation = np.corrcoef(pred1, pred2)[0, 1]
                report += f"   - {model1} vs {model2}: ìƒê´€ê³„ìˆ˜ {correlation:.3f}\n"
    
    report += f"""
ğŸ’¡ ì£¼ìš” íŠ¹ì§•:
   - ìµœê³  ì„±ëŠ¥: {best_model} (MAE {results[best_model]['MAE']:,.0f}ë§Œì›)
   - í‰ê·  {results[best_model]['MAE']/10000:.1f}ì–µì› ì˜¤ì°¨ë¡œ ì‹¤ìš©ì  ìˆ˜ì¤€
   - {best_accuracy:.0f}%ì˜ ê±°ë˜ê°€ Â±20% ì´ë‚´ë¡œ ì˜ˆì¸¡
   - ëª¨ë¸ê°„ ë†’ì€ ì¼ì¹˜ë„ë¡œ ì•ˆì •ì  ì˜ˆì¸¡

ğŸ¯ ê¶Œì¥ ì‚¬í•­:
   - ì¶”ì²œ ëª¨ë¸: {best_model}
   - ì¼ë°˜ ì‹œì„¸ ì°¸ê³ : ì ê·¹ ê¶Œì¥
   - íˆ¬ì ê²°ì •: Â±20% ì˜¤ì°¨ ê°ì•ˆí•˜ì—¬ í™œìš©
   - ì •ë°€ í‰ê°€: ì „ë¬¸ê°€ ìƒë‹´ ë³‘í–‰

=================================================================
"""
    
    report_path = 'reports/all_models_validation_report_2025.txt'
    with open(report_path, 'w', encoding='utf-8') as f:
        f.write(report)
    print(f"   âœ… ìµœì¢… ë³´ê³ ì„œ: {report_path}")
    
    # 13. ìµœì¢… ìš”ì•½
    print("\n" + "=" * 60)
    print("ğŸ‰ 2025 ì „ì²´ ëª¨ë¸ ì •í™•ë„ ê²€ì¦ ì™„ë£Œ!")
    print(f"ğŸ¥‡ ìµœê³  ëª¨ë¸: {best_model}")
    print(f"ğŸ“Š ìµœê³  ì„±ëŠ¥: MAE {results[best_model]['MAE']:,.0f}ë§Œì›, RÂ² {results[best_model]['RÂ²']:.3f}")
    print(f"ğŸ“Š Â±20% ì •í™•ë„: {best_accuracy:.1f}%")
    print(f"{practical_emoji} ì‹¤ìš©ì„±: {practical_level}")
    print(f"ğŸ“‚ ê²°ê³¼ í™•ì¸:")
    print(f"   - ì „ì²´ ê²°ê³¼: results/all_models_prediction_validation_2025.csv")
    print(f"   - ì„±ëŠ¥ ìš”ì•½: results/all_models_performance_summary_2025.json")
    print(f"   - ìµœì¢… ë³´ê³ ì„œ: reports/all_models_validation_report_2025.txt")
    print(f"   - ì‹œê°í™”: plots/ í´ë”")
    print("=" * 60)
    
    return {
        'results': results,
        'best_model': best_model,
        'results_df': results_df,
        'district_analysis': district_analysis,
        'price_analysis': price_analysis
    }

def create_default_mapping():
    """ê¸°ë³¸ ë§¤í•‘ ì •ë³´ ìƒì„±"""
    return {
        'gu_label_mapping': {
            'ê°•ë‚¨êµ¬': 0, 'ê°•ë™êµ¬': 1, 'ê°•ë¶êµ¬': 2, 'ê°•ì„œêµ¬': 3, 'ê´€ì•…êµ¬': 4,
            'ê´‘ì§„êµ¬': 5, 'êµ¬ë¡œêµ¬': 6, 'ê¸ˆì²œêµ¬': 7, 'ë…¸ì›êµ¬': 8, 'ë„ë´‰êµ¬': 9,
            'ë™ëŒ€ë¬¸êµ¬': 10, 'ë™ì‘êµ¬': 11, 'ë§ˆí¬êµ¬': 12, 'ì„œëŒ€ë¬¸êµ¬': 13, 'ì„œì´ˆêµ¬': 14,
            'ì„±ë™êµ¬': 15, 'ì„±ë¶êµ¬': 16, 'ì†¡íŒŒêµ¬': 17, 'ì–‘ì²œêµ¬': 18, 'ì˜ë“±í¬êµ¬': 19,
            'ìš©ì‚°êµ¬': 20, 'ì€í‰êµ¬': 21, 'ì¢…ë¡œêµ¬': 22, 'ì¤‘êµ¬': 23, 'ì¤‘ë‘êµ¬': 24
        }
    }

if __name__ == "__main__":
    print("ğŸ¯ 2025 ì„œìš¸ ì•„íŒŒíŠ¸ ê°€ê²© ì˜ˆì¸¡ ì „ì²´ ëª¨ë¸ ì •í™•ë„ ê²€ì¦")
    print("ğŸ¤– Random Forest vs XGBoost vs Linear Regression")
    print("ğŸ“Š êµ¬ë³„, ê°€ê²©ëŒ€ë³„, ëª¨ë¸ê°„ ì¼ì¹˜ë„ ìƒì„¸ ë¶„ì„")
    print()
    
    result = validate_all_models_2025()
    
    if result:
        print(f"\nğŸŠ ì „ì²´ ëª¨ë¸ ê²€ì¦ ì„±ê³µ! ğŸŠ")
        print(f"ìµœê³  ì„±ëŠ¥ ëª¨ë¸: {result['best_model']}")
        print(f"ëª¨ë“  ê²°ê³¼ íŒŒì¼ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!")
    else:
        print(f"\nâŒ ì „ì²´ ëª¨ë¸ ê²€ì¦ ì‹¤íŒ¨")