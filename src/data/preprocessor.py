"""
Seoul Apartment Price Prediction - Data Preprocessor
ì„œìš¸ ì•„íŒŒíŠ¸ ì‹¤ê±°ë˜ê°€ ë°ì´í„° ì „ì²˜ë¦¬ ë° EDA ëª¨ë“ˆ
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import warnings
from pathlib import Path
import sys

warnings.filterwarnings('ignore')

# í•œê¸€ í°íŠ¸ ì„¤ì •
plt.rcParams['font.family'] = 'Malgun Gothic'  # Windows
plt.rcParams['axes.unicode_minus'] = False

class SeoulApartmentPreprocessor:
    def __init__(self, data_path="data/raw/20250604_182224_seoul_real_estate.csv"):
        """
        ë°ì´í„° ì „ì²˜ë¦¬ê¸° ì´ˆê¸°í™”
        """
        self.data_path = data_path
        self.df = None
        self.train_data = None
        self.test_data = None
        self.feature_columns = []
        
        print("ğŸ  Seoul Apartment Price Prediction - ë°ì´í„° ì „ì²˜ë¦¬ ì‹œì‘")
        print("=" * 60)
        
    def load_data(self):
        """ë°ì´í„° ë¡œë“œ"""
        try:
            self.df = pd.read_csv(self.data_path, encoding='utf-8-sig')
            print(f"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(self.df):,}ê±´")
            print(f"ğŸ“Š ì»¬ëŸ¼ ìˆ˜: {len(self.df.columns)}ê°œ")
            
            # ê¸°ë³¸ ì»¬ëŸ¼ ì •ë³´ ì¶œë ¥
            print(f"ğŸ“‹ ì»¬ëŸ¼ ëª©ë¡:")
            for i, col in enumerate(self.df.columns, 1):
                print(f"  {i:2d}. {col}")
            
            # ë‚ ì§œ ì»¬ëŸ¼ ë³€í™˜
            if 'CTRT_DAY' in self.df.columns:
                self.df['CTRT_DAY'] = pd.to_datetime(self.df['CTRT_DAY'])
                # ğŸ¯ ì¤‘ìš”: ì‹¤ì œ ê³„ì•½ì¼ ê¸°ì¤€ìœ¼ë¡œ ì—°ë„ ì„¤ì •
                self.df['YEAR'] = self.df['CTRT_DAY'].dt.year
                self.df['MONTH'] = self.df['CTRT_DAY'].dt.month
                self.df['QUARTER'] = self.df['CTRT_DAY'].dt.quarter
                
                print(f"\nğŸ“… ê³„ì•½ì¼ ê¸°ì¤€ ì—°ë„ ë¶„í¬:")
                year_dist = self.df['YEAR'].value_counts().sort_index()
                for year, count in year_dist.items():
                    print(f"  {year}ë…„: {count:,}ê±´")
            
            # ğŸ”§ ë°ì´í„° ì •ë¦¬: 2022-2025ë…„ ë°ì´í„°ë§Œ ì‚¬ìš©
            original_len = len(self.df)
            self.df = self.df[(self.df['YEAR'] >= 2022) & (self.df['YEAR'] <= 2025)].copy()
            filtered_len = len(self.df)
            
            print(f"\nğŸ”§ ë°ì´í„° í•„í„°ë§:")
            print(f"  ì›ë³¸: {original_len:,}ê±´")
            print(f"  í•„í„°ë§ í›„ (2022-2025): {filtered_len:,}ê±´")
            print(f"  ì œì™¸ëœ ë°ì´í„°: {original_len - filtered_len:,}ê±´")
            
            # ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ ë³€í™˜
            numeric_cols = ['THING_AMT', 'ARCH_AREA', 'LAND_AREA', 'FLR', 'ARCH_YR', 'PYEONG', 'PRICE_PER_PYEONG']
            for col in numeric_cols:
                if col in self.df.columns:
                    self.df[col] = pd.to_numeric(self.df[col], errors='coerce')
            
            return True
        except Exception as e:
            print(f"âŒ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False
    
    def basic_info(self):
        """ê¸°ë³¸ ë°ì´í„° ì •ë³´"""
        if self.df is None:
            print("âŒ ë°ì´í„°ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return
        
        print("\nğŸ“‹ ë°ì´í„° ê¸°ë³¸ ì •ë³´")
        print("-" * 40)
        
        # ê¸°ê°„ ì •ë³´
        print(f"ğŸ“… ë°ì´í„° ê¸°ê°„: {self.df['CTRT_DAY'].min().strftime('%Y-%m-%d')} ~ {self.df['CTRT_DAY'].max().strftime('%Y-%m-%d')}")
        
        # ì‹¤ì œ ì—°ë„ í™•ì¸
        actual_years = sorted(self.df['YEAR'].unique())
        print(f"ğŸ“Š ì‹¤ì œ í¬í•¨ëœ ì—°ë„: {actual_years}")
        
        # ì—°ë„ë³„ ë¶„í¬
        print(f"\nğŸ“Š ì—°ë„ë³„ ê±°ë˜ ê±´ìˆ˜:")
        year_counts = self.df['YEAR'].value_counts().sort_index()
        total_count = 0
        for year, count in year_counts.items():
            percentage = (count / len(self.df)) * 100
            print(f"  {year}ë…„: {count:,}ê±´ ({percentage:.1f}%)")
            total_count += count
        
        print(f"  ì´í•©: {total_count:,}ê±´")
        
        # ì§€ì—­ë³„ ë¶„í¬ (ìƒìœ„ 10ê°œ)
        print(f"\nğŸ“ ìì¹˜êµ¬ë³„ ê±°ë˜ ê±´ìˆ˜ (ìƒìœ„ 10ê°œ):")
        district_counts = self.df['CGG_NM'].value_counts().head(10)
        for district, count in district_counts.items():
            percentage = (count / len(self.df)) * 100
            print(f"  {district}: {count:,}ê±´ ({percentage:.1f}%)")
        
        # ê°€ê²© ê¸°ë³¸ í†µê³„
        print(f"\nğŸ’° ê±°ë˜ê¸ˆì•¡ ê¸°ë³¸ í†µê³„:")
        price_stats = self.df['THING_AMT'].describe()
        print(f"  í‰ê· : {price_stats['mean']:,.0f}ë§Œì›")
        print(f"  ì¤‘ìœ„ìˆ˜: {price_stats['50%']:,.0f}ë§Œì›")
        print(f"  ìµœì €: {price_stats['min']:,.0f}ë§Œì›")
        print(f"  ìµœê³ : {price_stats['max']:,.0f}ë§Œì›")
        print(f"  í‘œì¤€í¸ì°¨: {price_stats['std']:,.0f}ë§Œì›")
        
        # ì›”ë³„ ë¶„í¬ (ê³„ì ˆì„± í™•ì¸)
        print(f"\nğŸ“… ì›”ë³„ ê±°ë˜ ê±´ìˆ˜:")
        month_counts = self.df['MONTH'].value_counts().sort_index()
        for month, count in month_counts.items():
            print(f"  {month:2d}ì›”: {count:,}ê±´")
        
    def data_quality_check(self):
        """ë°ì´í„° í’ˆì§ˆ ì²´í¬"""
        print("\nğŸ” ë°ì´í„° í’ˆì§ˆ ì²´í¬")
        print("-" * 40)
        
        # ê²°ì¸¡ì¹˜ ì²´í¬
        missing_data = self.df.isnull().sum()
        missing_percent = (missing_data / len(self.df)) * 100
        
        missing_df = pd.DataFrame({
            'ê²°ì¸¡ì¹˜_ê°œìˆ˜': missing_data,
            'ê²°ì¸¡ì¹˜_ë¹„ìœ¨(%)': missing_percent
        })
        
        missing_df = missing_df[missing_df['ê²°ì¸¡ì¹˜_ê°œìˆ˜'] > 0].sort_values('ê²°ì¸¡ì¹˜_ê°œìˆ˜', ascending=False)
        
        if not missing_df.empty:
            print("âš ï¸ ê²°ì¸¡ì¹˜ ë°œê²¬:")
            for col, row in missing_df.iterrows():
                print(f"  {col}: {row['ê²°ì¸¡ì¹˜_ê°œìˆ˜']:,}ê°œ ({row['ê²°ì¸¡ì¹˜_ë¹„ìœ¨(%)']:.1f}%)")
        else:
            print("âœ… ê²°ì¸¡ì¹˜ ì—†ìŒ")
        
        # ì´ìƒì¹˜ ì²´í¬ (IQR ë°©ë²•)
        Q1 = self.df['THING_AMT'].quantile(0.25)
        Q3 = self.df['THING_AMT'].quantile(0.75)
        IQR = Q3 - Q1
        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR
        
        outliers = self.df[(self.df['THING_AMT'] < lower_bound) | (self.df['THING_AMT'] > upper_bound)]
        print(f"\nğŸ“Š ê±°ë˜ê¸ˆì•¡ ì´ìƒì¹˜:")
        print(f"  ì´ìƒì¹˜ ê±´ìˆ˜: {len(outliers):,}ê±´ ({len(outliers)/len(self.df)*100:.1f}%)")
        print(f"  ì •ìƒ ë²”ìœ„: {lower_bound:,.0f}ë§Œì› ~ {upper_bound:,.0f}ë§Œì›")
        
        return missing_df, outliers
    
    def feature_engineering(self):
        """í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§"""
        print("\nğŸ”§ í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§")
        print("-" * 40)
        
        # ê¸°ì¡´ í¬ë¡¤ë§ì—ì„œ ìƒì„±ëœ íŒŒìƒë³€ìˆ˜ë“¤ í™•ì¸
        existing_features = []
        if 'PYEONG' in self.df.columns:
            existing_features.append('PYEONG')
        if 'PRICE_PER_PYEONG' in self.df.columns:
            existing_features.append('PRICE_PER_PYEONG')
        if 'PYEONG_GROUP' in self.df.columns:
            existing_features.append('PYEONG_GROUP')
        if 'ARCH_DECADE' in self.df.columns:
            existing_features.append('ARCH_DECADE')
        if 'PRICE_EUK' in self.df.columns:
            existing_features.append('PRICE_EUK (ì–µì›ë‹¨ìœ„)')
        
        if existing_features:
            print(f"âœ… ì´ë¯¸ ì¡´ì¬í•˜ëŠ” íŒŒìƒë³€ìˆ˜: {', '.join(existing_features)}")
        
        # ìƒˆë¡œìš´ í”¼ì²˜ë“¤ ìƒì„±
        # 1. ê±´ë¬¼ ë‚˜ì´ (ê³„ì•½ì—°ë„ ê¸°ì¤€)
        self.df['BUILDING_AGE'] = self.df['YEAR'] - self.df['ARCH_YR']
        
        # 2. í‰ë°©ë¯¸í„°ë‹¹ ê°€ê²©
        self.df['PRICE_PER_SQM'] = self.df['THING_AMT'] / self.df['ARCH_AREA']
        
        # 3. ê³„ì ˆ ì •ë³´
        season_map = {
            12: 'ê²¨ìš¸', 1: 'ê²¨ìš¸', 2: 'ê²¨ìš¸',
            3: 'ë´„', 4: 'ë´„', 5: 'ë´„',
            6: 'ì—¬ë¦„', 7: 'ì—¬ë¦„', 8: 'ì—¬ë¦„',
            9: 'ê°€ì„', 10: 'ê°€ì„', 11: 'ê°€ì„'
        }
        self.df['SEASON'] = self.df['MONTH'].map(season_map)
        
        # 4. ê³ ì¸µ/ì €ì¸µ êµ¬ë¶„
        self.df['FLOOR_GROUP'] = pd.cut(
            self.df['FLR'],
            bins=[0, 5, 10, 20, float('inf')],
            labels=['ì €ì¸µ(1-5ì¸µ)', 'ì¤‘ì¸µ(6-10ì¸µ)', 'ê³ ì¸µ(11-20ì¸µ)', 'ì´ˆê³ ì¸µ(21ì¸µì´ìƒ)']
        )
        
        # 5. ìƒì„¸ ê±´ë¬¼ ë‚˜ì´ êµ¬ê°„
        self.df['AGE_GROUP'] = pd.cut(
            self.df['BUILDING_AGE'],
            bins=[0, 5, 10, 20, 30, float('inf')],
            labels=['5ë…„ì´í•˜', '6-10ë…„', '11-20ë…„', '21-30ë…„', '30ë…„ì´ˆê³¼']
        )
        
        # 6. ê±°ë˜ ìœ í˜• (ì§ê±°ë˜/ì¤‘ê°œê±°ë˜)
        if 'DCLR_SE' in self.df.columns:
            self.df['IS_DIRECT_TRADE'] = (self.df['DCLR_SE'] == 'ì§ê±°ë˜').astype(int)
        
        # 7. ê°€ê²© êµ¬ê°„ ì„¸ë¶„í™”
        price_percentiles = self.df['THING_AMT'].quantile([0.25, 0.5, 0.75])
        self.df['PRICE_QUARTILE'] = pd.cut(
            self.df['THING_AMT'],
            bins=[0, price_percentiles[0.25], price_percentiles[0.5], price_percentiles[0.75], float('inf')],
            labels=['í•˜ìœ„25%', 'ì¤‘í•˜ìœ„25%', 'ì¤‘ìƒìœ„25%', 'ìƒìœ„25%']
        )
        
        # 8. ì§€ì—­ í”„ë¦¬ë¯¸ì—„ (êµ¬ë³„ í‰ê· ê°€ê²© ëŒ€ë¹„)
        district_avg_price = self.df.groupby('CGG_NM')['THING_AMT'].transform('mean')
        self.df['DISTRICT_PRICE_RATIO'] = self.df['THING_AMT'] / district_avg_price
        
        print(f"âœ… í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ ì™„ë£Œ")
        print(f"ğŸ“Š ì´ {len(self.df.columns)}ê°œ ì»¬ëŸ¼")
        
        # ìƒˆë¡œ ìƒì„±ëœ í”¼ì²˜ë“¤
        new_features = [
            'BUILDING_AGE', 'PRICE_PER_SQM', 'SEASON', 'FLOOR_GROUP', 
            'AGE_GROUP', 'IS_DIRECT_TRADE', 'PRICE_QUARTILE', 'DISTRICT_PRICE_RATIO'
        ]
        print(f"ğŸ†• ìƒˆë¡œ ìƒì„±ëœ í”¼ì²˜: {', '.join(new_features)}")
        
        return self.df
    
    def visualize_trends(self, save_plots=False):
        """ê¸°ë³¸ íŠ¸ë Œë“œ ì‹œê°í™” - ì‹¤ì œ ë°ì´í„°ë§Œ (Xì¶• ê°•ì œ ê³ ì •)"""
        print("\nğŸ“ˆ ë°ì´í„° ì‹œê°í™”")
        print("-" * 40)
        
        # ì‹¤ì œ ë°ì´í„° ì—°ë„ ë²”ìœ„ í™•ì¸
        actual_years = sorted(self.df['YEAR'].unique())
        print(f"ğŸ“Š ì‹¤ì œ ë°ì´í„° ì—°ë„: {actual_years}")
        
        # 1. ì—°ë„ë³„ í†µê³„ ê³„ì‚° (ì‹¤ì œ ë°ì´í„°ë§Œ)
        yearly_stats = self.df.groupby('YEAR').agg({
            'THING_AMT': ['mean', 'count'],
            'PRICE_PER_PYEONG': 'mean'
        }).round(0)
        yearly_stats.columns = ['í‰ê· ê±°ë˜ê°€', 'ê±°ë˜ê±´ìˆ˜', 'í‰ê· í‰ë‹¹ê°€']
        
        # 2. 4ê°œ ì°¨íŠ¸ ìƒì„±
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        
        # ì°¨íŠ¸ 1: ì—°ë„ë³„ í‰ê·  ê±°ë˜ê°€ (Xì¶• ì™„ì „ ê³ ì •)
        years = list(actual_years)  # ì‹¤ì œ ì—°ë„ë§Œ
        prices = [yearly_stats.loc[year, 'í‰ê· ê±°ë˜ê°€'] for year in years]
        
        axes[0,0].plot(range(len(years)), prices, marker='o', linewidth=3, markersize=10, color='#2E86AB')
        axes[0,0].set_title('ì—°ë„ë³„ í‰ê·  ê±°ë˜ê°€ ë³€í™”', fontsize=14, fontweight='bold')
        axes[0,0].set_ylabel('ê±°ë˜ê°€ (ë§Œì›)')
        axes[0,0].set_xlabel('ì—°ë„')
        axes[0,0].grid(True, alpha=0.3)
        # í•µì‹¬: Xì¶•ì„ ì¸ë±ìŠ¤ë¡œ ì„¤ì •í•˜ê³  ë¼ë²¨ë§Œ ì—°ë„ë¡œ
        axes[0,0].set_xticks(range(len(years)))
        axes[0,0].set_xticklabels(years)
        axes[0,0].set_xlim(-0.5, len(years)-0.5)
        
        # ê°’ í‘œì‹œ
        for i, (year, price) in enumerate(zip(years, prices)):
            axes[0,0].annotate(f'{price:,.0f}ë§Œì›', 
                             (i, price), textcoords="offset points", 
                             xytext=(0,10), ha='center', fontsize=9)
        
        # ì°¨íŠ¸ 2: ì—°ë„ë³„ ê±°ë˜ëŸ‰ (Xì¶• ì™„ì „ ê³ ì •)
        counts = [yearly_stats.loc[year, 'ê±°ë˜ê±´ìˆ˜'] for year in years]
        
        bars = axes[0,1].bar(range(len(years)), counts, color='#F18F01', alpha=0.8, width=0.5)
        axes[0,1].set_title('ì—°ë„ë³„ ê±°ë˜ëŸ‰ ë³€í™”', fontsize=14, fontweight='bold')
        axes[0,1].set_ylabel('ê±°ë˜ ê±´ìˆ˜')
        axes[0,1].set_xlabel('ì—°ë„')
        axes[0,1].set_xticks(range(len(years)))
        axes[0,1].set_xticklabels(years)
        axes[0,1].set_xlim(-0.5, len(years)-0.5)
        
        # ê°’ í‘œì‹œ
        for i, (bar, count) in enumerate(zip(bars, counts)):
            height = bar.get_height()
            axes[0,1].text(i, height + height*0.01,
                         f'{count:,}ê±´', ha='center', va='bottom', fontsize=9)
        
        # ì°¨íŠ¸ 3: êµ¬ë³„ í‰ê·  ê±°ë˜ê°€ (ìƒìœ„ 10ê°œ)
        district_price = self.df.groupby('CGG_NM')['THING_AMT'].mean().sort_values(ascending=True).tail(10)
        
        bars = axes[1,0].barh(range(len(district_price)), district_price.values, color='#A23B72')
        axes[1,0].set_yticks(range(len(district_price)))
        axes[1,0].set_yticklabels(district_price.index)
        axes[1,0].set_title('ìì¹˜êµ¬ë³„ í‰ê·  ê±°ë˜ê°€ (ìƒìœ„ 10ê°œ)', fontsize=14, fontweight='bold')
        axes[1,0].set_xlabel('í‰ê·  ê±°ë˜ê°€ (ë§Œì›)')
        
        # ê°’ í‘œì‹œ
        for i, (bar, price) in enumerate(zip(bars, district_price.values)):
            axes[1,0].text(price + price*0.01, i, f'{price:,.0f}ë§Œì›', 
                         ha='left', va='center', fontsize=9)
        
        # ì°¨íŠ¸ 4: í‰ìˆ˜ë³„ í‰ê·  ê±°ë˜ê°€
        if 'PYEONG_GROUP' in self.df.columns:
            # ê¸°ì¡´ PYEONG_GROUP ì‚¬ìš©
            pyeong_price = self.df.groupby('PYEONG_GROUP')['THING_AMT'].mean().dropna()
        else:
            # ìƒˆë¡œ ìƒì„±
            self.df['PYEONG_GROUP_SIMPLE'] = pd.cut(
                self.df['PYEONG'], 
                bins=[0, 10, 15, 20, 25, 30, 40, float('inf')],
                labels=['10í‰ë¯¸ë§Œ', '10-15í‰', '15-20í‰', '20-25í‰', '25-30í‰', '30-40í‰', '40í‰ì´ìƒ']
            )
            pyeong_price = self.df.groupby('PYEONG_GROUP_SIMPLE')['THING_AMT'].mean().dropna()
        
        if not pyeong_price.empty:
            bars = axes[1,1].bar(range(len(pyeong_price)), pyeong_price.values, color='#C73E1D')
            axes[1,1].set_xticks(range(len(pyeong_price)))
            axes[1,1].set_xticklabels(pyeong_price.index, rotation=45)
            axes[1,1].set_title('í‰ìˆ˜ë³„ í‰ê·  ê±°ë˜ê°€', fontsize=14, fontweight='bold')
            axes[1,1].set_ylabel('í‰ê·  ê±°ë˜ê°€ (ë§Œì›)')
            
            # ê°’ í‘œì‹œ
            for i, (bar, price) in enumerate(zip(bars, pyeong_price.values)):
                height = bar.get_height()
                axes[1,1].text(i, height + height*0.01,
                             f'{price:,.0f}', ha='center', va='bottom', fontsize=9, rotation=90)
        
        plt.tight_layout()
        
        if save_plots:
            Path('outputs/figures').mkdir(parents=True, exist_ok=True)
            plt.savefig('outputs/figures/basic_trends.png', dpi=300, bbox_inches='tight')
        
        plt.show()
        
        # ì‹¤ì œ ë°ì´í„° ìš”ì•½ ì¶œë ¥
        print(f"\nğŸ“Š ì—°ë„ë³„ ë°ì´í„° ìš”ì•½:")
        for year in years:
            year_data = self.df[self.df['YEAR'] == year]
            avg_price = year_data['THING_AMT'].mean()
            count = len(year_data)
            print(f"  {year}ë…„: {count:,}ê±´, í‰ê·  {avg_price:,.0f}ë§Œì›")
            
        print(f"\nğŸ“ˆ ì—°ë„ë³„ ì¦ê°ë¥ :")
        for i in range(1, len(years)):
            prev_year = years[i-1]
            curr_year = years[i]
            prev_price = prices[i-1]
            curr_price = prices[i]
            change_rate = ((curr_price - prev_price) / prev_price) * 100
            direction = "ğŸ“ˆ" if change_rate > 0 else "ğŸ“‰"
            print(f"  {prev_year}â†’{curr_year}: {direction} {change_rate:+.1f}%")
        
    def correlation_analysis(self):
        """ìƒê´€ê´€ê³„ ë¶„ì„"""
        print("\nğŸ” ìƒê´€ê´€ê³„ ë¶„ì„")
        print("-" * 40)
        
        # ìˆ˜ì¹˜í˜• ë³€ìˆ˜ë“¤ ì„ íƒ
        numeric_cols = [
            'THING_AMT', 'ARCH_AREA', 'LAND_AREA', 'FLR', 'ARCH_YR',
            'PYEONG', 'BUILDING_AGE', 'PRICE_PER_PYEONG', 'PRICE_PER_SQM',
            'YEAR', 'MONTH', 'QUARTER'
        ]
        
        # ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ ì„ íƒ
        available_cols = [col for col in numeric_cols if col in self.df.columns]
        
        correlation_matrix = self.df[available_cols].corr()
        
        # íˆíŠ¸ë§µ ìƒì„±
        plt.figure(figsize=(12, 10))
        mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))  # ìƒì‚¼ê° ë§ˆìŠ¤í¬
        
        sns.heatmap(correlation_matrix, 
                   mask=mask,
                   annot=True, 
                   cmap='RdYlBu_r', 
                   center=0,
                   square=True, 
                   fmt='.2f',
                   cbar_kws={"shrink": .8})
        
        plt.title('ë³€ìˆ˜ê°„ ìƒê´€ê´€ê³„ ë¶„ì„', fontsize=16, fontweight='bold', pad=20)
        plt.tight_layout()
        plt.show()
        
        # ê±°ë˜ê°€ì™€ ê°•í•œ ìƒê´€ê´€ê³„ë¥¼ ê°€ì§„ ë³€ìˆ˜ë“¤
        price_corr = correlation_matrix['THING_AMT'].abs().sort_values(ascending=False)
        print(f"\nğŸ’° ê±°ë˜ê°€(THING_AMT)ì™€ ìƒê´€ê´€ê³„ê°€ ë†’ì€ ë³€ìˆ˜ë“¤:")
        for var, corr in price_corr.head(10).items():
            if var != 'THING_AMT':
                print(f"  {var}: {corr:.3f}")
        
        return correlation_matrix
    
    def prepare_modeling_data(self):
        """ëª¨ë¸ë§ì„ ìœ„í•œ ë°ì´í„° ì¤€ë¹„"""
        print("\nğŸ¤– ëª¨ë¸ë§ ë°ì´í„° ì¤€ë¹„")
        print("-" * 40)
        
        # ë°ì´í„° íƒ€ì… í™•ì¸
        print("ğŸ“Š ì£¼ìš” ì»¬ëŸ¼ ë°ì´í„° íƒ€ì…:")
        key_columns = ['RCPT_YR', 'YEAR', 'THING_AMT', 'ARCH_AREA', 'FLR', 'BUILDING_AGE']
        for col in key_columns:
            if col in self.df.columns:
                print(f"  {col}: {self.df[col].dtype}")
        
        # âš ï¸ ì¤‘ìš”: ì‹¤ì œ ê³„ì•½ì¼ ê¸°ì¤€ìœ¼ë¡œ ë¶„í• 
        year_column = 'YEAR'  # CTRT_DAYì—ì„œ ì¶”ì¶œí•œ ì—°ë„ ì‚¬ìš©
        
        self.train_data = self.df[self.df[year_column] <= 2024].copy()  # í•™ìŠµìš© (2022-2024)
        self.test_data = self.df[self.df[year_column] == 2025].copy()   # í…ŒìŠ¤íŠ¸ìš© (2025)
        
        print(f"ğŸ“š í•™ìŠµ ë°ì´í„° (2022-2024): {len(self.train_data):,}ê±´")
        print(f"ğŸ§ª í…ŒìŠ¤íŠ¸ ë°ì´í„° (2025): {len(self.test_data):,}ê±´")
        print(f"âš ï¸  ì£¼ì˜: 2025ë…„ ë°ì´í„°ëŠ” ëª¨ë¸ ê²€ì¦ìš©ìœ¼ë¡œë§Œ ì‚¬ìš©!")
        
        # í•™ìŠµ ë°ì´í„° ì—°ë„ë³„ ë¶„í¬
        train_year_dist = self.train_data[year_column].value_counts().sort_index()
        print(f"\nğŸ“Š í•™ìŠµ ë°ì´í„° ì—°ë„ë³„ ë¶„í¬ (2022-2024):")
        for year, count in train_year_dist.items():
            percentage = (count / len(self.train_data)) * 100
            print(f"  {year}ë…„: {count:,}ê±´ ({percentage:.1f}%)")
        
        # ëª¨ë¸ë§ìš© í”¼ì²˜ ì„ íƒ (ê²°ì¸¡ì¹˜ê°€ ë§ì€ ì»¬ëŸ¼ ì œì™¸)
        self.feature_columns = [
            # ê¸°ë³¸ ì •ë³´
            'CGG_CD', 'STDG_CD',
            # ê±´ë¬¼ íŠ¹ì„± (í•µì‹¬)
            'ARCH_AREA', 'FLR', 'ARCH_YR', 'BUILDING_AGE',
            # ê¸°ì¡´ íŒŒìƒ ë³€ìˆ˜
            'PYEONG',
            # ì‹œê°„ ì •ë³´ (2025ë…„ ì œì™¸í•˜ê³  í•™ìŠµ)
            'YEAR', 'MONTH', 'QUARTER',
            # ìƒˆë¡œ ìƒì„±í•œ í”¼ì²˜ë“¤
            'PRICE_PER_SQM', 'DISTRICT_PRICE_RATIO'
        ]
        
        # ì¡°ê±´ë¶€ ì¶”ê°€í•  ì»¬ëŸ¼ë“¤
        
        # 1. LAND_AREA: ê²°ì¸¡ì¹˜ê°€ ì ê³  0ì´ ì•„ë‹Œ ê°’ì´ ë§ìœ¼ë©´ ì¶”ê°€
        if 'LAND_AREA' in self.df.columns:
            land_area_missing_rate = self.df['LAND_AREA'].isnull().sum() / len(self.df)
            land_area_nonzero_rate = (self.df['LAND_AREA'] > 0).sum() / len(self.df)
            if land_area_missing_rate < 0.05 and land_area_nonzero_rate > 0.3:
                self.feature_columns.append('LAND_AREA')
                print(f"  âœ… LAND_AREA ì¶”ê°€ (ê²°ì¸¡ë¥ : {land_area_missing_rate:.1%}, ìœ íš¨ê°’: {land_area_nonzero_rate:.1%})")
            else:
                print(f"  âŒ LAND_AREA ì œì™¸ (ê²°ì¸¡ë¥ : {land_area_missing_rate:.1%}, ìœ íš¨ê°’: {land_area_nonzero_rate:.1%})")
        
        # 2. ê±°ë˜ ìœ í˜• ê´€ë ¨ í”¼ì²˜
        if 'IS_DIRECT_TRADE' in self.df.columns:
            self.feature_columns.append('IS_DIRECT_TRADE')
            print(f"  âœ… IS_DIRECT_TRADE ì¶”ê°€")
        elif 'DCLR_SE' in self.df.columns:
            # DCLR_SEì—ì„œ ì§ê±°ë˜ ì—¬ë¶€ íŒŒìƒë³€ìˆ˜ ìƒì„±
            self.df['IS_DIRECT_TRADE'] = (self.df['DCLR_SE'] == 'ì§ê±°ë˜').astype(int)
            self.feature_columns.append('IS_DIRECT_TRADE')
            print(f"  âœ… IS_DIRECT_TRADE ìƒì„± ë° ì¶”ê°€")
        
        # 3. ì¤‘ê°œì—…ì†Œ ì§€ì—­ ì •ë³´ (ê²°ì¸¡ì¹˜ê°€ ì ìœ¼ë©´)
        if 'OPBIZ_RESTAGNT_SGG_NM' in self.df.columns:
            opbiz_missing_rate = self.df['OPBIZ_RESTAGNT_SGG_NM'].isnull().sum() / len(self.df)
            if opbiz_missing_rate < 0.1:  # 10% ë¯¸ë§Œì´ë©´ ì‚¬ìš©
                # ì¤‘ê°œì—…ì†Œê°€ ê°™ì€ êµ¬ì¸ì§€ ì—¬ë¶€
                self.df['SAME_DISTRICT_BROKER'] = (
                    self.df['CGG_NM'] == self.df['OPBIZ_RESTAGNT_SGG_NM']
                ).astype(int)
                self.feature_columns.append('SAME_DISTRICT_BROKER')
                print(f"  âœ… SAME_DISTRICT_BROKER ìƒì„± ë° ì¶”ê°€ (ê²°ì¸¡ë¥ : {opbiz_missing_rate:.1%})")
            else:
                print(f"  âŒ ì¤‘ê°œì—…ì†Œ ì •ë³´ ì œì™¸ (ê²°ì¸¡ë¥ : {opbiz_missing_rate:.1%})")
        
        # ì œì™¸ëœ ê³ ê²°ì¸¡ ì»¬ëŸ¼ë“¤ ì•Œë¦¼
        excluded_columns = ['RGHT_SE', 'RTRCN_DAY']  # 95% ì´ìƒ ê²°ì¸¡
        print(f"\nâŒ ì œì™¸ëœ ê³ ê²°ì¸¡ ì»¬ëŸ¼: {excluded_columns}")
        
        # ì¡´ì¬í•˜ëŠ” í”¼ì²˜ë§Œ ì„ íƒ
        available_features = [col for col in self.feature_columns if col in self.df.columns]
        excluded_features = [col for col in self.feature_columns if col not in self.df.columns]
        
        if excluded_features:
            print(f"âš ï¸ ì¡´ì¬í•˜ì§€ ì•ŠëŠ” í”¼ì²˜: {excluded_features}")
        
        self.feature_columns = available_features
        
        # ë²”ì£¼í˜• ë³€ìˆ˜ ì •ì˜
        categorical_columns = ['CGG_CD', 'STDG_CD']
        
        # ê²°ì¸¡ì¹˜ ì²˜ë¦¬ (í•™ìŠµ ë°ì´í„° ê¸°ì¤€ìœ¼ë¡œ!)
        print("\nğŸ”§ ê²°ì¸¡ì¹˜ ì²˜ë¦¬ (í•™ìŠµ ë°ì´í„° ê¸°ì¤€):")
        for col in self.feature_columns:
            train_missing = self.train_data[col].isnull().sum()
            test_missing = self.test_data[col].isnull().sum()
            
            if train_missing > 0 or test_missing > 0:
                if col in categorical_columns:
                    # ë²”ì£¼í˜•: í•™ìŠµ ë°ì´í„°ì˜ ìµœë¹ˆê°’ìœ¼ë¡œ ì±„ìš°ê¸°
                    mode_val = self.train_data[col].mode()
                    mode_val = mode_val[0] if not mode_val.empty else 'Unknown'
                    self.train_data[col] = self.train_data[col].fillna(mode_val)
                    self.test_data[col] = self.test_data[col].fillna(mode_val)
                    print(f"  {col}: {train_missing + test_missing}ê°œ â†’ '{mode_val}'ë¡œ ëŒ€ì²´")
                else:
                    # ìˆ˜ì¹˜í˜•: í•™ìŠµ ë°ì´í„°ì˜ ì¤‘ìœ„ìˆ˜ë¡œ ì±„ìš°ê¸°
                    median_val = self.train_data[col].median()
                    self.train_data[col] = self.train_data[col].fillna(median_val)
                    self.test_data[col] = self.test_data[col].fillna(median_val)
                    print(f"  {col}: {train_missing + test_missing}ê°œ â†’ {median_val}ë¡œ ëŒ€ì²´")
        
        print(f"\nâœ… ì„ íƒëœ í”¼ì²˜: {len(self.feature_columns)}ê°œ")
        print(f"ğŸ“‹ í”¼ì²˜ ëª©ë¡:")
        for i, col in enumerate(self.feature_columns, 1):
            col_type = "ë²”ì£¼í˜•" if col in categorical_columns else "ìˆ˜ì¹˜í˜•"
            print(f"  {i:2d}. {col} ({col_type})")
        
        # ë°ì´í„° ì €ì¥
        self.save_processed_data()
        
        return self.train_data, self.test_data, self.feature_columns
        print("\nğŸ”§ ê²°ì¸¡ì¹˜ ì²˜ë¦¬:")
        for col in self.feature_columns:
            train_missing = self.train_data[col].isnull().sum()
            test_missing = self.test_data[col].isnull().sum()
            
            if train_missing > 0 or test_missing > 0:
                if col in categorical_columns:
                    # ë²”ì£¼í˜•: ìµœë¹ˆê°’ìœ¼ë¡œ ì±„ìš°ê¸°
                    mode_val = self.train_data[col].mode()
                    mode_val = mode_val[0] if not mode_val.empty else 'Unknown'
                    self.train_data[col] = self.train_data[col].fillna(mode_val)
                    self.test_data[col] = self.test_data[col].fillna(mode_val)
                    print(f"  {col}: {train_missing + test_missing}ê°œ â†’ '{mode_val}'ë¡œ ëŒ€ì²´")
                else:
                    # ìˆ˜ì¹˜í˜•: ì¤‘ìœ„ìˆ˜ë¡œ ì±„ìš°ê¸°
                    median_val = self.train_data[col].median()
                    self.train_data[col] = self.train_data[col].fillna(median_val)
                    self.test_data[col] = self.test_data[col].fillna(median_val)
                    print(f"  {col}: {train_missing + test_missing}ê°œ â†’ {median_val}ë¡œ ëŒ€ì²´")
        
        print(f"\nâœ… ì„ íƒëœ í”¼ì²˜: {len(self.feature_columns)}ê°œ")
        print(f"ğŸ“‹ í”¼ì²˜ ëª©ë¡:")
        for i, col in enumerate(self.feature_columns, 1):
            col_type = "ë²”ì£¼í˜•" if col in categorical_columns else "ìˆ˜ì¹˜í˜•"
            print(f"  {i:2d}. {col} ({col_type})")
        
        # ë°ì´í„° ì €ì¥
        self.save_processed_data()
        
        return self.train_data, self.test_data, self.feature_columns
    
    def save_processed_data(self):
        """ì „ì²˜ë¦¬ëœ ë°ì´í„° ì €ì¥"""
        try:
            # í´ë” ìƒì„±
            Path("data/processed").mkdir(exist_ok=True)
            
            # ë°ì´í„° ì €ì¥
            self.train_data.to_csv('data/processed/train_data_2022_2024.csv', 
                                 index=False, encoding='utf-8-sig')
            self.test_data.to_csv('data/processed/test_data_2025.csv', 
                                index=False, encoding='utf-8-sig')
            
            # í”¼ì²˜ ì •ë³´ ì €ì¥
            feature_info = {
                'feature_columns': self.feature_columns,
                'target_column': 'THING_AMT',
                'categorical_columns': ['CGG_CD', 'STDG_CD']
            }
            
            import json
            with open('data/processed/feature_info.json', 'w', encoding='utf-8') as f:
                json.dump(feature_info, f, ensure_ascii=False, indent=2)
            
            print(f"\nğŸ’¾ ì „ì²˜ë¦¬ëœ ë°ì´í„° ì €ì¥ ì™„ë£Œ!")
            print(f"  ğŸ“ í•™ìŠµ ë°ì´í„°: data/processed/train_data_2022_2024.csv")
            print(f"  ğŸ“ í…ŒìŠ¤íŠ¸ ë°ì´í„°: data/processed/test_data_2025.csv")
            print(f"  ğŸ“ í”¼ì²˜ ì •ë³´: data/processed/feature_info.json")
            
        except Exception as e:
            print(f"âŒ ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def generate_summary_report(self):
        """ì „ì²´ ìš”ì•½ ë³´ê³ ì„œ"""
        print("\n" + "="*60)
        print("ğŸ“Š ì„œìš¸ ì•„íŒŒíŠ¸ ì‹¤ê±°ë˜ê°€ ë°ì´í„° ë¶„ì„ ìš”ì•½ ë³´ê³ ì„œ")
        print("="*60)
        
        print(f"\nğŸ“ˆ ë°ì´í„° ê°œìš”:")
        print(f"  â€¢ ì´ ê±°ë˜ê±´ìˆ˜: {len(self.df):,}ê±´")
        print(f"  â€¢ ë¶„ì„ê¸°ê°„: {self.df['CTRT_DAY'].min().strftime('%Y-%m-%d')} ~ {self.df['CTRT_DAY'].max().strftime('%Y-%m-%d')}")
        print(f"  â€¢ ì‹¤ì œ ì—°ë„: {sorted(self.df['YEAR'].unique())}")
        print(f"  â€¢ ëŒ€ìƒì§€ì—­: ì„œìš¸ì‹œ {self.df['CGG_NM'].nunique()}ê°œ ìì¹˜êµ¬")
        
        print(f"\nğŸ’° ê±°ë˜ê°€ í˜„í™©:")
        print(f"  â€¢ í‰ê·  ê±°ë˜ê°€: {self.df['THING_AMT'].mean():,.0f}ë§Œì›")
        print(f"  â€¢ ì¤‘ìœ„ ê±°ë˜ê°€: {self.df['THING_AMT'].median():,.0f}ë§Œì›")
        print(f"  â€¢ ìµœê³  ê±°ë˜ê°€: {self.df['THING_AMT'].max():,.0f}ë§Œì›")
        print(f"  â€¢ í‰ê·  í‰ë‹¹ê°€: {self.df['PRICE_PER_PYEONG'].mean():,.0f}ë§Œì›/í‰")
        
        print(f"\nğŸ  ê±´ë¬¼ íŠ¹ì„±:")
        print(f"  â€¢ í‰ê·  ì „ìš©ë©´ì : {self.df['ARCH_AREA'].mean():.1f}ã¡")
        print(f"  â€¢ í‰ê·  í‰ìˆ˜: {self.df['PYEONG'].mean():.1f}í‰")
        print(f"  â€¢ í‰ê·  ê±´ë¬¼ë‚˜ì´: {self.df['BUILDING_AGE'].mean():.1f}ë…„")
        print(f"  â€¢ í‰ê·  ì¸µìˆ˜: {self.df['FLR'].mean():.1f}ì¸µ")
        
        # ì—°ë„ë³„ ì¦ê°€ìœ¨ (2022-2025 ì „ì²´)
        actual_years = sorted(self.df['YEAR'].unique())
        if len(actual_years) > 1:
            yearly_avg = self.df.groupby('YEAR')['THING_AMT'].mean()
            growth_rates = yearly_avg.pct_change() * 100
            print(f"\nğŸ“ˆ ì—°ë„ë³„ í‰ê·  ê±°ë˜ê°€ ë³€í™”ìœ¨:")
            for year, rate in growth_rates.dropna().items():
                direction = "ğŸ“ˆ" if rate > 0 else "ğŸ“‰"
                print(f"  â€¢ {year}ë…„: {direction} {rate:+.1f}%")
        
        print(f"\nğŸ¯ ëª¨ë¸ë§ ì¤€ë¹„:")
        print(f"  â€¢ í•™ìŠµ ë°ì´í„°: {len(self.train_data):,}ê±´ (2022-2024)")
        print(f"  â€¢ í…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(self.test_data):,}ê±´ (2025)")
        print(f"  â€¢ í”¼ì²˜ ê°œìˆ˜: {len(self.feature_columns)}ê°œ")
        
        print(f"\nâœ… ì „ì²˜ë¦¬ ì™„ë£Œ! ë‹¤ìŒ ë‹¨ê³„: ëª¨ë¸ í•™ìŠµ")


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    # ì „ì²˜ë¦¬ê¸° ìƒì„±
    preprocessor = SeoulApartmentPreprocessor()
    
    # 1. ë°ì´í„° ë¡œë“œ
    if not preprocessor.load_data():
        return None
    
    # 2. ê¸°ë³¸ ì •ë³´ í™•ì¸
    preprocessor.basic_info()
    
    # 3. ë°ì´í„° í’ˆì§ˆ ì²´í¬
    missing_df, outliers = preprocessor.data_quality_check()
    
    # 4. í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§
    processed_df = preprocessor.feature_engineering()
    
    # 5. ì‹œê°í™”
    preprocessor.visualize_trends()
    
    # 6. ìƒê´€ê´€ê³„ ë¶„ì„
    correlation_matrix = preprocessor.correlation_analysis()
    
    # 7. ëª¨ë¸ë§ ë°ì´í„° ì¤€ë¹„
    train_data, test_data, feature_columns = preprocessor.prepare_modeling_data()
    
    # 8. ìš”ì•½ ë³´ê³ ì„œ
    preprocessor.generate_summary_report()
    
    return preprocessor

if __name__ == "__main__":
    preprocessor = main()