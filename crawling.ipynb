{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "973d0f66",
   "metadata": {},
   "source": [
    "## ë¶€ë™ì‚° ì‹¤ê±°ë˜ê°€ Crawling ã„±ã„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c31edc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ ì„œìš¸ì‹œ ë¶€ë™ì‚° ì‹¤ê±°ë˜ê°€ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘\n",
      "==================================================\n",
      "ğŸ“Œ ì „ì²´ ë°ì´í„° ê°œìˆ˜: 1959ê±´\n",
      "ğŸ“¥ ë°ì´í„° ìˆ˜ì§‘ ì¤‘: 1~1000ë²ˆì§¸ (1000ê±´)\n",
      "ğŸ“¥ ë°ì´í„° ìˆ˜ì§‘ ì¤‘: 1001~1959ë²ˆì§¸ (959ê±´)\n",
      "âœ… ì´ ìˆ˜ì§‘ëœ ë°ì´í„°: 1959ê±´\n",
      "\n",
      "ğŸ“Š XML ë°ì´í„° íŒŒì‹± ì¤‘...\n",
      "ì´ ë°ì´í„° ê°œìˆ˜: 1959\n",
      "ê²°ê³¼ ì½”ë“œ: INFO-000, ë©”ì‹œì§€: ì •ìƒ ì²˜ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤\n",
      "íŒŒì‹±ëœ ë°ì´í„° í–‰ ìˆ˜: 1959\n",
      "\n",
      "ğŸ”§ ë°ì´í„° ì „ì²˜ë¦¬ ì¤‘...\n",
      "\n",
      "ğŸ“‹ DataFrame ì •ë³´:\n",
      "í–‰ ìˆ˜: 1959\n",
      "ì—´ ìˆ˜: 25\n",
      "\n",
      "ì»¬ëŸ¼ ëª©ë¡:\n",
      " 1. RCPT_YR\n",
      " 2. CGG_CD\n",
      " 3. CGG_NM\n",
      " 4. STDG_CD\n",
      " 5. STDG_NM\n",
      " 6. LOTNO_SE\n",
      " 7. LOTNO_SE_NM\n",
      " 8. MNO\n",
      " 9. SNO\n",
      "10. BLDG_NM\n",
      "11. CTRT_DAY\n",
      "12. THING_AMT\n",
      "13. ARCH_AREA\n",
      "14. LAND_AREA\n",
      "15. FLR\n",
      "16. RGHT_SE\n",
      "17. RTRCN_DAY\n",
      "18. ARCH_YR\n",
      "19. BLDG_USG\n",
      "20. DCLR_SE\n",
      "21. OPBIZ_RESTAGNT_SGG_NM\n",
      "22. ARCH_DECADE\n",
      "23. PYEONG\n",
      "24. PYEONG_GROUP\n",
      "25. PRICE_EUK\n",
      "\n",
      "ğŸ” ìƒ˜í”Œ ë°ì´í„° (ìƒìœ„ 3ê°œ):\n",
      "  CGG_NM STDG_NM                  BLDG_NM   CTRT_DAY  THING_AMT  ARCH_AREA\n",
      "0    ê°•ë‚¨êµ¬    ì••êµ¬ì •ë™  í˜„ëŒ€14ì°¨(203,204,205,206ë™) 2025-06-02     520000      84.98\n",
      "1    ê°•ë‚¨êµ¬     ê°œí¬ë™                ê°œí¬ë˜ë¯¸ì•ˆí¬ë ˆìŠ¤íŠ¸ 2025-06-02     320000      84.90\n",
      "2    ê°•ë‚¨êµ¬     ìê³¡ë™                  ë˜ë¯¸ì•ˆê°•ë‚¨íì¦ˆ 2025-05-30     215000     101.94\n",
      "\n",
      "ğŸ’¾ CSV íŒŒì¼ ì €ì¥ ì¤‘...\n",
      "âœ… ë°ì´í„° ì €ì¥ ì™„ë£Œ: data/20250604_163131_seoul_real_estate.csv\n",
      "ğŸ“Š ì´ 1959ê±´ì˜ ë°ì´í„°\n",
      "ğŸ’° í‰ê·  ê±°ë˜ê°€: 282,413ë§Œì›\n",
      "ğŸ’° ìµœê³  ê±°ë˜ê°€: 1,305,000ë§Œì›\n",
      "\n",
      "ğŸ¢ ê±´ì¶•ì—°ëŒ€ë³„ ë¶„í¬:\n",
      "ARCH_DECADE\n",
      "2000ë…„ëŒ€    566\n",
      "1990ë…„ëŒ€    436\n",
      "1980ë…„ëŒ€    346\n",
      "2010ë…„ëŒ€    331\n",
      "2020ë…„ëŒ€    137\n",
      "Name: count, dtype: int64\n",
      "\n",
      "ğŸ“ í‰ìˆ˜ëŒ€ë³„ ë¶„í¬:\n",
      "PYEONG_GROUP\n",
      "20í‰í˜•ëŒ€    829\n",
      "10í‰í˜•ëŒ€    523\n",
      "30í‰í˜•ëŒ€    349\n",
      "40í‰í˜•ëŒ€    156\n",
      "50í‰í˜•ëŒ€     50\n",
      "Name: count, dtype: int64\n",
      "\n",
      "âœ… ì‘ì—… ì™„ë£Œ!\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "\n",
    "def get_seoul_real_estate_data():\n",
    "    # API íŒŒë¼ë¯¸í„° ì„¤ì •\n",
    "    # 1 ì ‘ìˆ˜ì—°ë„\n",
    "    RCPT_YR = 2025          # í˜„ì¬ 2025ë…„ ë°ì´í„° -> ì—°ë„ ë³€í™˜ í•˜ë©´ ë¨\n",
    "    var1 = RCPT_YR\n",
    "\n",
    "    # 2 ìì¹˜êµ¬ì½”ë“œ\n",
    "    CGG_CD = '%20'\n",
    "    var2 = CGG_CD\n",
    "\n",
    "    # 3 ìì¹˜êµ¬ëª…\n",
    "    CGG_NM = 'ê°•ë‚¨êµ¬'       # ì„œìš¸ì‹œ í–‰ì •êµ¬ ì…ë ¥\n",
    "    var3 = CGG_NM\n",
    "\n",
    "    # 4 ë²•ì •ë™ì½”ë“œ\n",
    "    STDG_CD = '%20'\n",
    "    var4 = STDG_CD\n",
    "\n",
    "    # 5 ì§€ë²ˆêµ¬ë¶„\n",
    "    LOTNO_SE = '%20'\n",
    "    var5 = LOTNO_SE\n",
    "\n",
    "    # 6 ì§€ë²ˆêµ¬ë¶„ëª…\n",
    "    LOTNO_SE_NM = '%20'\n",
    "    var6 = LOTNO_SE_NM\n",
    "\n",
    "    # 7 ë³¸ë²ˆ\n",
    "    MNO = '%20'\n",
    "    var7 = MNO\n",
    "\n",
    "    # 8 ë¶€ë²ˆ\n",
    "    SNO = '%20'\n",
    "    var8 = SNO\n",
    "\n",
    "    # 9 ê±´ë¬¼ëª…\n",
    "    BLDG_NM = '%20'\n",
    "    var9 = BLDG_NM\n",
    "\n",
    "    # 10 ê³„ì•½ì¼\n",
    "    CTRT_DAY = '%20'\n",
    "    var10 = CTRT_DAY\n",
    "\n",
    "    # 11 ê±´ë¬¼ìš©ë„ \t\t\t# [ì•„íŒŒíŠ¸/ë‹¨ë…ë‹¤ê°€êµ¬/ì—°ë¦½ë‹¤ì„¸ëŒ€/ì˜¤í”¼ìŠ¤í…”] íƒ 1\n",
    "    BLDG_USG = 'ì•„íŒŒíŠ¸' \n",
    "    var11 = BLDG_USG\n",
    "\n",
    "    vKey = '646e476d7a62757235397547714b41'\n",
    "    base_url = f'http://openapi.seoul.go.kr:8088/{vKey}/xml/tbLnOpendataRtmsV'\n",
    "    \n",
    "    try:\n",
    "        # 1. ì „ì²´ ë°ì´í„° ê°œìˆ˜ í™•ì¸\n",
    "        count_url = f'{base_url}/1/1/{var1}/{var2}/{var3}/{var4}/{var5}/{var6}/{var7}/{var8}/{var9}/{var10}/{var11}'\n",
    "        count_response = requests.get(count_url)\n",
    "        root = ET.fromstring(count_response.content)\n",
    "        \n",
    "        # ì—ëŸ¬ ì²´í¬\n",
    "        result = root.find('RESULT')\n",
    "        if result is not None:\n",
    "            code = result.find('CODE')\n",
    "            if code is not None and code.text != 'INFO-000':\n",
    "                message = result.find('MESSAGE')\n",
    "                print(f\"ğŸš¨ API ì˜¤ë¥˜: {code.text} - {message.text if message is not None else 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜'}\")\n",
    "                return None\n",
    "        \n",
    "        total_count = int(root.find('list_total_count').text)\n",
    "        print(f\"ğŸ“Œ ì „ì²´ ë°ì´í„° ê°œìˆ˜: {total_count}ê±´\")\n",
    "        \n",
    "        # 2. 1000ê±´ì”© ë‚˜ëˆ„ì–´ì„œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°\n",
    "        all_data = []\n",
    "        max_per_request = 1000  # API ì œí•œì‚¬í•­\n",
    "        \n",
    "        for start_idx in range(1, total_count + 1, max_per_request):\n",
    "            end_idx = min(start_idx + max_per_request - 1, total_count)\n",
    "            \n",
    "            print(f\"ğŸ“¥ ë°ì´í„° ìˆ˜ì§‘ ì¤‘: {start_idx}~{end_idx}ë²ˆì§¸ ({len(range(start_idx, end_idx + 1))}ê±´)\")\n",
    "            \n",
    "            data_url = f'{base_url}/{start_idx}/{end_idx}/{var1}/{var2}/{var3}/{var4}/{var5}/{var6}/{var7}/{var8}/{var9}/{var10}/{var11}'\n",
    "            \n",
    "            # 3. ê° ë°°ì¹˜ ë°ì´í„° ìš”ì²­\n",
    "            response = requests.get(data_url, timeout=30)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            # XML íŒŒì‹±í•˜ì—¬ ë°ì´í„° ì¶”ì¶œ\n",
    "            batch_root = ET.fromstring(response.content)\n",
    "            \n",
    "            # ì—ëŸ¬ ì²´í¬\n",
    "            batch_result = batch_root.find('RESULT')\n",
    "            if batch_result is not None:\n",
    "                batch_code = batch_result.find('CODE')\n",
    "                if batch_code is not None and batch_code.text != 'INFO-000':\n",
    "                    batch_message = batch_result.find('MESSAGE')\n",
    "                    print(f\"âš ï¸ ë°°ì¹˜ {start_idx}~{end_idx} ì˜¤ë¥˜: {batch_code.text} - {batch_message.text if batch_message is not None else 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜'}\")\n",
    "                    continue\n",
    "            \n",
    "            # row ë°ì´í„° ì¶”ì¶œ\n",
    "            for row in batch_root.findall('row'):\n",
    "                row_data = {}\n",
    "                for element in row:\n",
    "                    tag_name = element.tag\n",
    "                    tag_value = element.text if element.text else ''\n",
    "                    row_data[tag_name] = tag_value\n",
    "                all_data.append(row_data)\n",
    "            \n",
    "            # API í˜¸ì¶œ ê°„ê²© (ì„œë²„ ë¶€í•˜ ë°©ì§€)\n",
    "            import time\n",
    "            time.sleep(0.1)\n",
    "        \n",
    "        print(f\"âœ… ì´ ìˆ˜ì§‘ëœ ë°ì´í„°: {len(all_data)}ê±´\")\n",
    "        \n",
    "        # 4. ì „ì²´ ë°ì´í„°ë¥¼ XML í˜•íƒœë¡œ ì¬êµ¬ì„±\n",
    "        combined_xml = f\"\"\"<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
    "<response>\n",
    "    <list_total_count>{total_count}</list_total_count>\n",
    "    <RESULT>\n",
    "        <CODE>INFO-000</CODE>\n",
    "        <MESSAGE>ì •ìƒ ì²˜ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤</MESSAGE>\n",
    "    </RESULT>\n",
    "\"\"\"\n",
    "        \n",
    "        for data in all_data:\n",
    "            combined_xml += \"    <row>\\n\"\n",
    "            for key, value in data.items():\n",
    "                combined_xml += f\"        <{key}>{value}</{key}>\\n\"\n",
    "            combined_xml += \"    </row>\\n\"\n",
    "        \n",
    "        combined_xml += \"</response>\"\n",
    "        \n",
    "        return combined_xml.encode('utf-8')\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"ğŸš¨ API í˜¸ì¶œ ì˜¤ë¥˜: {e}\")\n",
    "        return None\n",
    "    except ET.ParseError as e:\n",
    "        print(f\"ğŸš¨ XML íŒŒì‹± ì˜¤ë¥˜: {e}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"ğŸš¨ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def parse_xml_to_dataframe(xml_content):\n",
    "    \"\"\"XML ë°ì´í„°ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜\"\"\"\n",
    "    if xml_content is None:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    try:\n",
    "        # XML íŒŒì‹±\n",
    "        root = ET.fromstring(xml_content)\n",
    "        \n",
    "        # ì „ì²´ ë°ì´í„° ê°œìˆ˜ í™•ì¸\n",
    "        total_count = root.find('list_total_count')\n",
    "        if total_count is not None:\n",
    "            print(f\"ì´ ë°ì´í„° ê°œìˆ˜: {total_count.text}\")\n",
    "        \n",
    "        # ê²°ê³¼ ìƒíƒœ í™•ì¸\n",
    "        result = root.find('RESULT')\n",
    "        if result is not None:\n",
    "            code = result.find('CODE')\n",
    "            message = result.find('MESSAGE')\n",
    "            if code is not None and message is not None:\n",
    "                print(f\"ê²°ê³¼ ì½”ë“œ: {code.text}, ë©”ì‹œì§€: {message.text}\")\n",
    "        \n",
    "        # ë°ì´í„° ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”\n",
    "        data_list = []\n",
    "        \n",
    "        # ê° row ìš”ì†Œ ì²˜ë¦¬\n",
    "        for row in root.findall('row'):\n",
    "            row_data = {}\n",
    "            \n",
    "            # ëª¨ë“  í•˜ìœ„ ìš”ì†Œ ì¶”ì¶œ\n",
    "            for element in row:\n",
    "                tag_name = element.tag\n",
    "                tag_value = element.text if element.text else ''\n",
    "                row_data[tag_name] = tag_value\n",
    "            \n",
    "            data_list.append(row_data)\n",
    "        \n",
    "        print(f\"íŒŒì‹±ëœ ë°ì´í„° í–‰ ìˆ˜: {len(data_list)}\")\n",
    "        \n",
    "        # DataFrame ìƒì„±\n",
    "        df = pd.DataFrame(data_list)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    except ET.ParseError as e:\n",
    "        print(f\"XML íŒŒì‹± ì˜¤ë¥˜: {e}\")\n",
    "        return pd.DataFrame()\n",
    "    except Exception as e:\n",
    "        print(f\"ë°ì´í„° ì²˜ë¦¬ ì˜¤ë¥˜: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "\n",
    "def preprocess_dataframe(df):\n",
    "    \"\"\"DataFrame ì „ì²˜ë¦¬ ë° ì¶”ê°€ ì»¬ëŸ¼ ìƒì„±\"\"\"\n",
    "    if df.empty:\n",
    "        return df\n",
    "    \n",
    "    # ìˆ«ìí˜• ë°ì´í„° ë³€í™˜\n",
    "    numeric_columns = ['RCPT_YR', 'CGG_CD', 'STDG_CD', 'MNO', 'SNO', \n",
    "                      'THING_AMT', 'ARCH_AREA', 'LAND_AREA', 'FLR', 'ARCH_YR']\n",
    "    \n",
    "    for col in numeric_columns:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    \n",
    "    # ë‚ ì§œ ë³€í™˜\n",
    "    date_columns = ['CTRT_DAY', 'RTRCN_DAY']\n",
    "    for col in date_columns:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_datetime(df[col], format='%Y%m%d', errors='coerce')\n",
    "    \n",
    "    # ê±´ì¶•ì—°ëŒ€ ê·¸ë£¹í™”\n",
    "    if 'ARCH_YR' in df.columns:\n",
    "        df['ARCH_DECADE'] = df['ARCH_YR'].apply(\n",
    "            lambda x: f\"{(x//10)*10}ë…„ëŒ€\" if pd.notna(x) else \"ë¯¸ìƒ\"\n",
    "        )\n",
    "    \n",
    "    # í‰ìˆ˜ ê³„ì‚° (ê±´ì¶•ë©´ì  ê¸°ì¤€)\n",
    "    if 'ARCH_AREA' in df.columns:\n",
    "        df['PYEONG'] = df['ARCH_AREA'] * 0.3025  # ã¡ â†’ í‰ ë³€í™˜\n",
    "        df['PYEONG_GROUP'] = df['PYEONG'].apply(\n",
    "            lambda x: f\"{int(x//10)*10}í‰í˜•ëŒ€\" if pd.notna(x) and x > 0 else \"ë¯¸ìƒ\"\n",
    "        )\n",
    "    \n",
    "    # ê±°ë˜ê¸ˆì•¡ì„ ì–µì› ë‹¨ìœ„ë¡œ ë³€í™˜\n",
    "    if 'THING_AMT' in df.columns:\n",
    "        df['PRICE_EUK'] = df['THING_AMT'] / 10000\n",
    "    \n",
    "    # ë°ì´í„° ì •ë ¬ (ìµœì‹  ê³„ì•½ì¼ ìˆœ)\n",
    "    if 'CTRT_DAY' in df.columns:\n",
    "        df = df.sort_values('CTRT_DAY', ascending=False)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def save_to_csv(df, filename=None):\n",
    "    \"\"\"DataFrameì„ CSV íŒŒì¼ë¡œ ì €ì¥\"\"\"\n",
    "    if df.empty:\n",
    "        print(\"ì €ì¥í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return\n",
    "    \n",
    "    # data ë””ë ‰í† ë¦¬ ìƒì„±\n",
    "    import os\n",
    "    os.makedirs('data', exist_ok=True)\n",
    "    \n",
    "    if filename is None:\n",
    "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        filename = f'data/{timestamp}_seoul_real_estate.csv'\n",
    "    \n",
    "    try:\n",
    "        df.to_csv(filename, index=False, encoding='utf-8-sig')\n",
    "        print(f\"âœ… ë°ì´í„° ì €ì¥ ì™„ë£Œ: {filename}\")\n",
    "        print(f\"ğŸ“Š ì´ {len(df)}ê±´ì˜ ë°ì´í„°\")\n",
    "        \n",
    "        # ê¸°ë³¸ í†µê³„ ì¶œë ¥\n",
    "        if 'THING_AMT' in df.columns:\n",
    "            print(f\"ğŸ’° í‰ê·  ê±°ë˜ê°€: {df['THING_AMT'].mean():,.0f}ë§Œì›\")\n",
    "            print(f\"ğŸ’° ìµœê³  ê±°ë˜ê°€: {df['THING_AMT'].max():,.0f}ë§Œì›\")\n",
    "        \n",
    "        if 'ARCH_DECADE' in df.columns:\n",
    "            print(\"\\nğŸ¢ ê±´ì¶•ì—°ëŒ€ë³„ ë¶„í¬:\")\n",
    "            print(df['ARCH_DECADE'].value_counts().head())\n",
    "        \n",
    "        if 'PYEONG_GROUP' in df.columns:\n",
    "            print(\"\\nğŸ“ í‰ìˆ˜ëŒ€ë³„ ë¶„í¬:\")\n",
    "            print(df['PYEONG_GROUP'].value_counts().head())\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"íŒŒì¼ ì €ì¥ ì˜¤ë¥˜: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜\"\"\"\n",
    "    print(\"ğŸš€ ì„œìš¸ì‹œ ë¶€ë™ì‚° ì‹¤ê±°ë˜ê°€ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # 1. XML ë°ì´í„° ìˆ˜ì§‘\n",
    "    xml_content = get_seoul_real_estate_data()\n",
    "    \n",
    "    if xml_content is None:\n",
    "        print(\"âŒ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨\")\n",
    "        return\n",
    "    \n",
    "    # 2. XML íŒŒì‹± ë° DataFrame ë³€í™˜\n",
    "    print(\"\\nğŸ“Š XML ë°ì´í„° íŒŒì‹± ì¤‘...\")\n",
    "    df = parse_xml_to_dataframe(xml_content)\n",
    "    \n",
    "    if df.empty:\n",
    "        print(\"âŒ íŒŒì‹±ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return\n",
    "    \n",
    "    # 3. ë°ì´í„° ì „ì²˜ë¦¬\n",
    "    print(\"\\nğŸ”§ ë°ì´í„° ì „ì²˜ë¦¬ ì¤‘...\")\n",
    "    df = preprocess_dataframe(df)\n",
    "    \n",
    "    # 4. DataFrame ì •ë³´ ì¶œë ¥\n",
    "    print(\"\\nğŸ“‹ DataFrame ì •ë³´:\")\n",
    "    print(f\"í–‰ ìˆ˜: {len(df)}\")\n",
    "    print(f\"ì—´ ìˆ˜: {len(df.columns)}\")\n",
    "    print(\"\\nì»¬ëŸ¼ ëª©ë¡:\")\n",
    "    for i, col in enumerate(df.columns, 1):\n",
    "        print(f\"{i:2d}. {col}\")\n",
    "    \n",
    "    # 5. ìƒ˜í”Œ ë°ì´í„° ì¶œë ¥\n",
    "    print(\"\\nğŸ” ìƒ˜í”Œ ë°ì´í„° (ìƒìœ„ 3ê°œ):\")\n",
    "    print(df.head(3)[['CGG_NM', 'STDG_NM', 'BLDG_NM', 'CTRT_DAY', 'THING_AMT', 'ARCH_AREA']].to_string())\n",
    "    \n",
    "    # 6. CSV ì €ì¥\n",
    "    print(\"\\nğŸ’¾ CSV íŒŒì¼ ì €ì¥ ì¤‘...\")\n",
    "    save_to_csv(df)\n",
    "    \n",
    "    print(\"\\nâœ… ì‘ì—… ì™„ë£Œ!\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "# ì‹¤í–‰\n",
    "if __name__ == \"__main__\":\n",
    "    df = main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06dcb9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import re\n",
    "import requests\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "driver.maximize_window()\n",
    "\n",
    "#response = requests.get(url)\n",
    "#print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "57d91106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://openapi.seoul.go.kr:8088/646e476d7a62757235397547714b41/xml/tbLnOpendataRtmsV/1/5/2025/11500/ê°•ì„œêµ¬/10500/%20/%20/%20/%20/%20/%20/ì•„íŒŒíŠ¸\n"
     ]
    }
   ],
   "source": [
    "vKey = '646e476d7a62757235397547714b41'\n",
    "url = f'http://openapi.seoul.go.kr:8088/{vKey}/xml/tbLnOpendataRtmsV/1/5/{var1}/{var2}/{var3}/{var4}/{var5}/{var6}/{var7}/{var8}/{var9}/{var10}/{var11}'\n",
    "\n",
    "print(url)\n",
    "\n",
    "driver.get(url)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
